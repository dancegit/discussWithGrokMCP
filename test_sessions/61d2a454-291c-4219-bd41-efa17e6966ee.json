{
  "id": "61d2a454-291c-4219-bd41-efa17e6966ee",
  "topic": "Analyze this codebase structure",
  "created_at": "2025-09-20T10:23:54.443466",
  "updated_at": "2025-09-20T10:24:11.265109",
  "messages": [
    {
      "role": "user",
      "content": "Context:\n\n--- File: lib/session_manager.py ---\n\"\"\"\nSession Manager - State tracking with checkpointing and crash recovery.\n\"\"\"\n\nimport asyncio\nimport uuid\nimport time\nimport os\nfrom typing import Optional, List, Dict, Any\nfrom datetime import datetime\nfrom dataclasses import dataclass, field, asdict\nimport logging\nimport json\n\nfrom .storage_manager import StorageManager\nfrom .grok_client import GrokResponse\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass Session:\n    \"\"\"Represents a discussion session.\"\"\"\n    id: str\n    topic: str\n    status: str = \"active\"  # active, completed, failed, paused\n    created: str = field(default_factory=lambda: datetime.now().isoformat())\n    max_iterations: int = 3\n    iterations_completed: int = 0\n    has_baseline: bool = False\n    baseline_path: Optional[str] = None\n    responses: List[Dict[str, Any]] = field(default_factory=list)\n    context_files: List[str] = field(default_factory=list)\n    total_tokens: int = 0\n    quality_scores: List[float] = field(default_factory=list)\n    checkpoints: List[Dict[str, Any]] = field(default_factory=list)\n    last_checkpoint: Optional[str] = None\n    metadata: Dict[str, Any] = field(default_factory=dict)\n    \n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert session to dictionary.\"\"\"\n        return asdict(self)\n    \n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> \"Session\":\n        \"\"\"Create session from dictionary.\"\"\"\n        return cls(**data)\n\n\nclass SessionManager:\n    \"\"\"Manages discussion sessions with checkpointing and recovery.\"\"\"\n    \n    def __init__(self, storage_manager: StorageManager):\n        \"\"\"Initialize session manager.\n        \n        Args:\n            storage_manager: Storage manager instance\n        \"\"\"\n        self.storage = storage_manager\n        self.active_sessions: Dict[str, Session] = {}\n        self.checkpoint_interval = 60  # seconds\n        self._checkpoint_tasks: Dict[str, asyncio.Task] = {}\n        self.max_active_sessions = int(os.getenv('MAX_ACTIVE_SESSIONS', '100'))  # Max sessions in memory\n        self.session_access_times: Dict[str, datetime] = {}  # Track last access for LRU\n        self._cleanup_task = None  # Periodic cleanup task\n        self._start_cleanup_task()  # Start periodic cleanup\n        \n    def generate_session_id(self, prefix: str = \"session\") -> str:\n        \"\"\"Generate a unique session ID.\n        \n        Args:\n            prefix: Prefix for the session ID\n            \n        Returns:\n            Unique session identifier\n        \"\"\"\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        unique_id = str(uuid.uuid4())[:8]\n        return f\"{prefix}_{timestamp}_{unique_id}\"\n    \n    async def create_session(\n        self,\n        topic: str,\n        max_iterations: int = 3,\n        session_type: str = \"discuss\"\n    ) -> Session:\n        \"\"\"Create a new discussion session.\n        \n        Args:\n            topic: Discussion topic\n            max_iterations: Maximum iterations allowed\n            session_type: Type of session (discuss, ask, problem)\n            \n        Returns:\n            Created session object\n        \"\"\"\n        session_id = self.generate_session_id(prefix=session_type)\n        \n        session = Session(\n            id=session_id,\n            topic=topic,\n            max_iterations=max_iterations,\n            metadata={\n                \"type\": session_type,\n                \"version\": \"1.0.0\"\n            }\n        )\n        \n        # Check if we need to evict before adding\n        await self._check_and_evict_sessions()\n        \n        # Add to active sessions\n        self.active_sessions[session_id] = session\n        self.session_access_times[session_id] = datetime.now()\n        \n        # Save initial state\n        await self._save_session(session)\n        \n        # Start checkpoint task\n        self._start_checkpoint_task(session_id)\n        \n        logger.info(f\"Created session {session_id} for topic: {topic}\")\n        return session\n    \n    async def get_session(self, session_id: str) -> Optional[Session]:\n        \"\"\"Get a session by ID.\n        \n        Args:\n            session_id: Session identifier\n            \n        Returns:\n            Session object or None if not found\n        \"\"\"\n        # Check active sessions first\n        if session_id in self.active_sessions:\n            # Update access time for LRU\n            self.session_access_times[session_id] = datetime.now()\n            return self.active_sessions[session_id]\n        \n        # Try to load from storage\n        session_data = await self.storage.load_session(session_id)\n        if session_data:\n            # Check if we need to evict before loading\n            await self._check_and_evict_sessions()\n            \n            session = Session.from_dict(session_data)\n            self.active_sessions[session_id] = session\n            self.session_access_times[session_id] = datetime.now()\n            \n            # Restart checkpoint task if session is active\n            if session.status == \"active\":\n                self._start_checkpoint_task(session_id)\n            \n            return session\n        \n        return None\n    \n    async def update_session(\n        self,\n        session_id: str,\n        response: Optional[GrokResponse] = None,\n        iteration_complete: bool = False,\n        status: Optional[str] = None\n    ) -> Session:\n        \"\"\"Update session state.\n        \n        Args:\n            session_id: Session identifier\n            response: Grok response to add\n            iteration_complete: Whether an iteration was completed\n            status: New status for session\n            \n        Returns:\n            Updated session object\n        \"\"\"\n        session = await self.get_session(session_id)\n        if not session:\n            raise ValueError(f\"Session {session_id} not found\")\n        \n        # Update response if provided\n        if response:\n            session.responses.append({\n                \"iteration\": session.iterations_completed,\n                \"content\": response.content,\n                \"tokens\": response.tokens_used,\n                \"timestamp\": response.timestamp\n            })\n            session.total_tokens += response.tokens_used\n        \n        # Update iteration count\n        if iteration_complete:\n            session.iterations_completed += 1\n            \n            # Check if max iterations reached\n            if session.iterations_completed >= session.max_iterations:\n                session.status = \"completed\"\n        \n        # Update status if provided\n        if status:\n            session.status = status\n        \n        # Save updated session\n        await self._save_session(session)\n        \n        # Stop checkpoint task if session is no longer active\n        if session.status != \"active\":\n            self._stop_checkpoint_task(session_id)\n        \n        return session\n    \n    async def add_checkpoint(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Create a checkpoint for the session.\n        \n        Args:\n            session_id: Session identifier\n            \n        Returns:\n            Checkpoint data\n        \"\"\"\n        session = await self.get_session(session_id)\n        if not session:\n            raise ValueError(f\"Session {session_id} not found\")\n        \n        checkpoint = {\n            \"timestamp\": datetime.now().isoformat(),\n            \"iteration\": session.iterations_completed,\n            \"status\": session.status,\n            \"tokens_used\": session.total_tokens,\n            \"responses_count\": len(session.responses)\n        }\n        \n        session.checkpoints.append(checkpoint)\n        session.last_checkpoint = checkpoint[\"timestamp\"]\n        \n        # Save session with checkpoint\n        await self._save_session(session)\n        \n        logger.debug(f\"Created checkpoint for session {session_id}\")\n        return checkpoint\n    \n    async def recover_session(self, session_id: str) -> Optional[Session]:\n        \"\"\"Recover a session from last checkpoint.\n        \n        Args:\n            session_id: Session identifier\n            \n        Returns:\n            Recovered session or None if recovery fails\n        \"\"\"\n        try:\n            # Load session from storage\n            session_data = await self.storage.load_session(session_id)\n            if not session_data:\n                logger.error(f\"No saved data found for session {session_id}\")\n                return None\n            \n            session = Session.from_dict(session_data)\n            \n            # Check if recovery is needed\n            if session.status == \"active\" and session.checkpoints:\n                last_checkpoint = session.checkpoints[-1]\n                logger.info(f\"Recovering session {session_id} from checkpoint: {last_checkpoint['timestamp']}\")\n                \n                # Restore state from checkpoint\n                session.iterations_completed = last_checkpoint[\"iteration\"]\n                session.total_tokens = last_checkpoint[\"tokens_used\"]\n                \n                # Mark as recovered\n                session.metadata[\"recovered\"] = True\n                session.metadata[\"recovery_time\"] = datetime.now().isoformat()\n            \n            # Add to active sessions\n            self.active_sessions[session_id] = session\n            \n            # Restart checkpoint task if still active\n            if session.status == \"active\":\n                self._start_checkpoint_task(session_id)\n            \n            return session\n            \n        except Exception as e:\n            logger.error(f\"Failed to recover session {session_id}: {e}\")\n            return None\n    \n    async def pause_session(self, session_id: str) -> Session:\n        \"\"\"Pause an active session.\n        \n        Args:\n            session_id: Session identifier\n            \n        Returns:\n            Paused session\n        \"\"\"\n        session = await self.get_session(session_id)\n        if not session:\n            raise ValueError(f\"Session {session_id} not found\")\n        \n        if session.status != \"active\":\n            raise ValueError(f\"Cannot pause session in {session.status} state\")\n        \n        session.status = \"paused\"\n        session.metadata[\"paused_at\"] = datetime.now().isoformat()\n        \n        # Create checkpoint before pausing\n        await self.add_checkpoint(session_id)\n        \n        # Save and stop checkpoint task\n        await self._save_session(session)\n        self._stop_checkpoint_task(session_id)\n        \n        logger.info(f\"Paused session {session_id}\")\n        return session\n    \n    async def resume_session(self, session_id: str) -> Session:\n        \"\"\"Resume a paused session.\n        \n        Args:\n            session_id: Session identifier\n            \n        Returns:\n            Resumed session\n        \"\"\"\n        session = await self.get_session(session_id)\n        if not session:\n            raise ValueError(f\"Session {session_id} not found\")\n        \n        if session.status != \"paused\":\n            raise ValueError(f\"Cannot resume session in {session.status} state\")\n        \n        session.status = \"active\"\n        session.metadata[\"resumed_at\"] = datetime.now().isoformat()\n        \n        # Save and restart checkpoint task\n        await self._save_session(session)\n        self._start_checkpoint_task(session_id)\n        \n        logger.info(f\"Resumed session {session_id}\")\n        return session\n    \n    def calculate_quality_score(self, response: str) -> float:\n        \"\"\"Calculate quality score for a response.\n        \n        Args:\n            response: Response content to score\n            \n        Returns:\n            Quality score between 0 and 1\n        \"\"\"\n        score = 0.0\n        factors = 0\n        \n        # Length factor (longer responses often more detailed)\n        if len(response) > 100:\n            score += 0.2\n            factors += 1\n        \n        # Code presence (indicates actionable content)\n        if \"```\" in response:\n            score += 0.3\n            factors += 1\n        \n        # Structure (headers indicate organization)\n        if \"#\" in response or \"##\" in response:\n            score += 0.2\n            factors += 1\n        \n        # Lists (indicate structured information)\n        if \"- \" in response or \"* \" in response or \"1. \" in response:\n            score += 0.15\n            factors += 1\n        \n        # Specificity (technical terms)\n        technical_terms = [\"implement\", \"function\", \"class\", \"method\", \"algorithm\", \n                          \"optimize\", \"architecture\", \"performance\", \"security\"]\n        if any(term in response.lower() for term in technical_terms):\n            score += 0.15\n            factors += 1\n        \n        # Normalize score\n        if factors > 0:\n            return min(1.0, score)\n        \n        # Default score for minimal responses\n        return 0.3\n    \n    async def _save_session(self, session: Session):\n        \"\"\"Save session to storage.\n        \n        Args:\n            session: Session to save\n        \"\"\"\n        await self.storage.save_session(session.id, session.to_dict())\n    \n    def _start_checkpoint_task(self, session_id: str):\n        \"\"\"Start periodic checkpoint task for a session.\n        \n        Args:\n            session_id: Session identifier\n        \"\"\"\n        if session_id in self._checkpoint_tasks:\n            return  # Task already running\n        \n        async def checkpoint_loop():\n            \"\"\"Periodic checkpoint loop.\"\"\"\n            while session_id in self.active_sessions:\n                await asyncio.sleep(self.checkpoint_interval)\n                \n                if session_id in self.active_sessions:\n                    session = self.active_sessions[session_id]\n                    if session.status == \"active\":\n                        await self.add_checkpoint(session_id)\n        \n        task = asyncio.create_task(checkpoint_loop())\n        self._checkpoint_tasks[session_id] = task\n    \n    def _stop_checkpoint_task(self, session_id: str):\n        \"\"\"Stop checkpoint task for a session.\n        \n        Args:\n            session_id: Session identifier\n        \"\"\"\n        if session_id in self._checkpoint_tasks:\n            task = self._checkpoint_tasks[session_id]\n            task.cancel()\n            del self._checkpoint_tasks[session_id]\n    \n    async def _check_and_evict_sessions(self):\n        \"\"\"Check if eviction is needed and evict LRU sessions.\"\"\"\n        if len(self.active_sessions) >= self.max_active_sessions:\n            # Find the least recently used session\n            if self.session_access_times:\n                lru_session_id = min(\n                    self.session_access_times.keys(),\n                    key=lambda k: self.session_access_times[k]\n                )\n                \n                # Save before evicting\n                if lru_session_id in self.active_sessions:\n                    await self._save_session(self.active_sessions[lru_session_id])\n                    \n                    # Stop checkpoint task\n                    self._stop_checkpoint_task(lru_session_id)\n                    \n                    # Remove from memory\n                    del self.active_sessions[lru_session_id]\n                    del self.session_access_times[lru_session_id]\n                    \n                    logger.info(f\"Evicted LRU session {lru_session_id} to free memory\")\n    \n    async def cleanup_inactive_sessions(self, timeout_hours: int = None):\n        \"\"\"Clean up inactive sessions.\n        \n        Args:\n            timeout_hours: Hours of inactivity before cleanup\n        \"\"\"\n        from datetime import timedelta\n        \n        if timeout_hours is None:\n            timeout_hours = float(os.getenv('SESSION_INACTIVITY_TIMEOUT_HOURS', '2'))\n        \n        cutoff_time = datetime.now() - timedelta(hours=timeout_hours)\n        sessions_to_remove = []\n        \n        for session_id, session in self.active_sessions.items():\n            # Check last access time\n            if session_id in self.session_access_times:\n                last_access = self.session_access_times[session_id]\n                if last_access < cutoff_time and session.status != \"active\":\n                    sessions_to_remove.append(session_id)\n        \n        # Remove inactive sessions\n        for session_id in sessions_to_remove:\n            # Save before removing\n            await self._save_session(self.active_sessions[session_id])\n            self._stop_checkpoint_task(session_id)\n            del self.active_sessions[session_id]\n            if session_id in self.session_access_times:\n                del self.session_access_times[session_id]\n            logger.info(f\"Cleaned up inactive session {session_id}\")\n    \n    def get_active_sessions(self) -> List[Session]:\n        \"\"\"Get all active sessions.\n        \n        Returns:\n            List of active sessions\n        \"\"\"\n        return [s for s in self.active_sessions.values() if s.status == \"active\"]\n    \n    def get_session_stats(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Get statistics for a session.\n        \n        Args:\n            session_id: Session identifier\n            \n        Returns:\n            Session statistics\n        \"\"\"\n        session = self.active_sessions.get(session_id)\n        if not session:\n            return {}\n        \n        avg_quality = sum(session.quality_scores) / len(session.quality_scores) if session.quality_scores else 0\n        \n        return {\n            \"id\": session.id,\n            \"topic\": session.topic,\n            \"status\": session.status,\n            \"created\": session.created,\n            \"iterations\": f\"{session.iterations_completed}/{session.max_iterations}\",\n            \"total_tokens\": session.total_tokens,\n            \"responses\": len(session.responses),\n            \"checkpoints\": len(session.checkpoints),\n            \"average_quality\": round(avg_quality, 2),\n            \"has_baseline\": session.has_baseline\n        }\n    \n    def _start_cleanup_task(self):\n        \"\"\"Start periodic cleanup task for memory management.\"\"\"\n        async def periodic_cleanup():\n            \"\"\"Run cleanup periodically.\"\"\"\n            cleanup_interval_hours = float(os.getenv('MEMORY_CLEANUP_INTERVAL_HOURS', '1'))\n            cleanup_interval_seconds = cleanup_interval_hours * 3600\n            \n            while True:\n                try:\n                    await asyncio.sleep(cleanup_interval_seconds)\n                    \n                    # Run cleanup for inactive sessions\n                    await self.cleanup_inactive_sessions()\n                    \n                    # Log memory status\n                    logger.info(f\"Memory cleanup completed. Active sessions: {len(self.active_sessions)}\")\n                    \n                except asyncio.CancelledError:\n                    break\n                except Exception as e:\n                    logger.error(f\"Error in periodic cleanup: {e}\")\n        \n        # Create and store the task\n        self._cleanup_task = asyncio.create_task(periodic_cleanup())\n    \n    def stop_cleanup_task(self):\n        \"\"\"Stop the periodic cleanup task.\"\"\"\n        if self._cleanup_task and not self._cleanup_task.done():\n            self._cleanup_task.cancel()\n\n--- File: lib/__init__.py ---\n\"\"\"\nGrok MCP Server Library - Core modules for intelligent Grok discussions.\n\"\"\"\n\nfrom .grok_client import GrokClient\nfrom .storage_manager import StorageManager\nfrom .session_manager import SessionManager\nfrom .context_analyzer import ContextAnalyzer\nfrom .baseline_generator import BaselineGenerator\n\n__all__ = [\n    \"GrokClient\",\n    \"StorageManager\",\n    \"SessionManager\",\n    \"ContextAnalyzer\",\n    \"BaselineGenerator\",\n]\n\n__version__ = \"0.1.0\"\n\n--- File: lib/storage_manager.py ---\n\"\"\"\nStorage Manager - Local persistence for sessions, responses, and baselines.\n\"\"\"\n\nimport json\nimport os\nimport asyncio\nimport aiofiles\nfrom pathlib import Path\nfrom typing import Optional, List, Dict, Any\nfrom datetime import datetime\nimport logging\nimport hashlib\n\nlogger = logging.getLogger(__name__)\n\n\nclass StorageManager:\n    \"\"\"Manages local storage for Grok discussions.\"\"\"\n    \n    def __init__(self, storage_path: str = \"./grok_discussions\"):\n        \"\"\"Initialize storage manager.\n        \n        Args:\n            storage_path: Base path for storage directories\n        \"\"\"\n        self.storage_path = Path(storage_path)\n        self.sessions_path = self.storage_path / \"sessions\"\n        self.responses_path = self.storage_path / \"responses\"\n        self.baselines_path = self.storage_path / \"baselines\"\n        self.metadata_file = self.storage_path / \"metadata.json\"\n        \n        # Create directories if they don't exist\n        self._ensure_directories()\n        \n        # Load or initialize metadata\n        self.metadata = self._load_metadata()\n        \n    def _ensure_directories(self):\n        \"\"\"Ensure all storage directories exist.\"\"\"\n        for path in [self.sessions_path, self.responses_path, self.baselines_path]:\n            path.mkdir(parents=True, exist_ok=True)\n    \n    def _load_metadata(self) -> Dict[str, Any]:\n        \"\"\"Load metadata from file or create new.\"\"\"\n        if self.metadata_file.exists():\n            try:\n                with open(self.metadata_file, 'r') as f:\n                    return json.load(f)\n            except Exception as e:\n                logger.error(f\"Failed to load metadata: {e}\")\n        \n        # Initialize new metadata\n        return {\n            \"version\": \"1.0.0\",\n            \"created\": datetime.now().isoformat(),\n            \"sessions\": {},\n            \"total_sessions\": 0,\n            \"total_responses\": 0,\n            \"index\": {}  # For search functionality\n        }\n    \n    async def save_metadata(self):\n        \"\"\"Save metadata to file.\"\"\"\n        try:\n            async with aiofiles.open(self.metadata_file, 'w') as f:\n                await f.write(json.dumps(self.metadata, indent=2))\n        except Exception as e:\n            logger.error(f\"Failed to save metadata: {e}\")\n    \n    async def save_session(self, session_id: str, session_data: Dict[str, Any]) -> str:\n        \"\"\"Save a session to storage.\n        \n        Args:\n            session_id: Unique session identifier\n            session_data: Session data to save\n            \n        Returns:\n            Path to saved session file\n        \"\"\"\n        file_path = self.sessions_path / f\"{session_id}.json\"\n        \n        try:\n            # Add timestamp if not present\n            if \"saved_at\" not in session_data:\n                session_data[\"saved_at\"] = datetime.now().isoformat()\n            \n            async with aiofiles.open(file_path, 'w') as f:\n                await f.write(json.dumps(session_data, indent=2))\n            \n            # Update metadata\n            self.metadata[\"sessions\"][session_id] = {\n                \"path\": str(file_path),\n                \"saved_at\": session_data[\"saved_at\"],\n                \"topic\": session_data.get(\"topic\", \"Unknown\")\n            }\n            self.metadata[\"total_sessions\"] += 1\n            await self.save_metadata()\n            \n            logger.info(f\"Saved session {session_id} to {file_path}\")\n            return str(file_path)\n            \n        except Exception as e:\n            logger.error(f\"Failed to save session {session_id}: {e}\")\n            raise\n    \n    async def load_session(self, session_id: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Load a session from storage.\n        \n        Args:\n            session_id: Session identifier to load\n            \n        Returns:\n            Session data or None if not found\n        \"\"\"\n        file_path = self.sessions_path / f\"{session_id}.json\"\n        \n        if not file_path.exists():\n            logger.warning(f\"Session {session_id} not found\")\n            return None\n        \n        # Check file size to prevent excessive loading\n        file_size = file_path.stat().st_size\n        max_size = int(os.getenv('MAX_SESSION_SIZE_MB', '50')) * 1024 * 1024  # Default 50 MB\n        if file_size > max_size:\n            logger.warning(f\"Session {session_id} too large ({file_size} bytes, max {max_size} bytes), skipping load\")\n            return None\n        \n        try:\n            async with aiofiles.open(file_path, 'r') as f:\n                content = await f.read()\n                return json.loads(content)\n        except Exception as e:\n            logger.error(f\"Failed to load session {session_id}: {e}\")\n            return None\n    \n    async def save_response(\n        self,\n        session_id: str,\n        response: str,\n        iteration: int = 0,\n        metadata: Optional[Dict[str, Any]] = None\n    ) -> str:\n        \"\"\"Save a Grok response.\n        \n        Args:\n            session_id: Associated session ID\n            response: Response content\n            iteration: Iteration number in discussion\n            metadata: Additional metadata\n            \n        Returns:\n            Path to saved response file\n        \"\"\"\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        filename = f\"response_{session_id}_{iteration}_{timestamp}.md\"\n        file_path = self.responses_path / filename\n        \n        try:\n            # Prepare response document\n            document = f\"# Grok Response\\n\\n\"\n            document += f\"**Session**: {session_id}\\n\"\n            document += f\"**Iteration**: {iteration}\\n\"\n            document += f\"**Timestamp**: {datetime.now().isoformat()}\\n\"\n            \n            if metadata:\n                document += f\"\\n## Metadata\\n\"\n                for key, value in metadata.items():\n                    document += f\"- **{key}**: {value}\\n\"\n            \n            document += f\"\\n## Response\\n\\n{response}\"\n            \n            async with aiofiles.open(file_path, 'w') as f:\n                await f.write(document)\n            \n            # Update metadata\n            self.metadata[\"total_responses\"] += 1\n            \n            # Add to search index\n            response_hash = hashlib.md5(response.encode()).hexdigest()[:8]\n            if \"responses\" not in self.metadata[\"index\"]:\n                self.metadata[\"index\"][\"responses\"] = {}\n            \n            self.metadata[\"index\"][\"responses\"][response_hash] = {\n                \"session_id\": session_id,\n                \"iteration\": iteration,\n                \"path\": str(file_path),\n                \"timestamp\": timestamp\n            }\n            \n            await self.save_metadata()\n            \n            logger.info(f\"Saved response for session {session_id} to {file_path}\")\n            return str(file_path)\n            \n        except Exception as e:\n            logger.error(f\"Failed to save response: {e}\")\n            raise\n    \n    async def save_baseline(\n        self,\n        session_id: str,\n        baseline: str,\n        topic: str\n    ) -> str:\n        \"\"\"Save a baseline document.\n        \n        Args:\n            session_id: Associated session ID\n            baseline: Baseline document content\n            topic: Discussion topic\n            \n        Returns:\n            Path to saved baseline file\n        \"\"\"\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        filename = f\"baseline_{session_id}_{timestamp}.md\"\n        file_path = self.baselines_path / filename\n        \n        try:\n            # Prepare baseline document\n            document = f\"# Baseline Document\\n\\n\"\n            document += f\"**Topic**: {topic}\\n\"\n            document += f\"**Session**: {session_id}\\n\"\n            document += f\"**Generated**: {datetime.now().isoformat()}\\n\"\n            document += f\"\\n---\\n\\n{baseline}\"\n            \n            async with aiofiles.open(file_path, 'w') as f:\n                await f.write(document)\n            \n            # Add to index\n            if \"baselines\" not in self.metadata[\"index\"]:\n                self.metadata[\"index\"][\"baselines\"] = {}\n            \n            self.metadata[\"index\"][\"baselines\"][session_id] = {\n                \"topic\": topic,\n                \"path\": str(file_path),\n                \"timestamp\": timestamp\n            }\n            \n            await self.save_metadata()\n            \n            logger.info(f\"Saved baseline for session {session_id} to {file_path}\")\n            return str(file_path)\n            \n        except Exception as e:\n            logger.error(f\"Failed to save baseline: {e}\")\n            raise\n    \n    async def list_sessions(\n        self,\n        status: Optional[str] = None,\n        limit: int = 10\n    ) -> List[Dict[str, Any]]:\n        \"\"\"List stored sessions.\n        \n        Args:\n            status: Filter by status (active/completed/failed)\n            limit: Maximum sessions to return\n            \n        Returns:\n            List of session metadata\n        \"\"\"\n        sessions = []\n        \n        for session_id, info in self.metadata.get(\"sessions\", {}).items():\n            # Load session to check status\n            session_data = await self.load_session(session_id)\n            if session_data:\n                if status and session_data.get(\"status\") != status:\n                    continue\n                    \n                sessions.append({\n                    \"id\": session_id,\n                    \"topic\": info.get(\"topic\", \"Unknown\"),\n                    \"status\": session_data.get(\"status\", \"unknown\"),\n                    \"created\": session_data.get(\"created\"),\n                    \"iterations\": session_data.get(\"iterations_completed\", 0),\n                    \"path\": info.get(\"path\")\n                })\n        \n        # Sort by creation time (newest first)\n        sessions.sort(key=lambda x: x.get(\"created\", \"\"), reverse=True)\n        \n        return sessions[:limit]\n    \n    async def search_responses(\n        self,\n        query: str,\n        session_id: Optional[str] = None\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Search through stored responses.\n        \n        Args:\n            query: Search query\n            session_id: Optional filter by session\n            \n        Returns:\n            List of matching responses with metadata\n        \"\"\"\n        results = []\n        query_lower = query.lower()\n        \n        # Search through response files\n        for response_file in self.responses_path.glob(\"*.md\"):\n            try:\n                async with aiofiles.open(response_file, 'r') as f:\n                    content = await f.read()\n                    \n                if query_lower in content.lower():\n                    # Extract session ID from filename\n                    parts = response_file.stem.split(\"_\")\n                    if len(parts) >= 3:\n                        file_session_id = parts[1]\n                        \n                        if session_id and file_session_id != session_id:\n                            continue\n                        \n                        results.append({\n                            \"file\": str(response_file),\n                            \"session_id\": file_session_id,\n                            \"snippet\": self._extract_snippet(content, query_lower)\n                        })\n                        \n            except Exception as e:\n                logger.error(f\"Error searching file {response_file}: {e}\")\n        \n        return results\n    \n    def _extract_snippet(self, content: str, query: str, context_chars: int = 100) -> str:\n        \"\"\"Extract a snippet around the query match.\n        \n        Args:\n            content: Full content\n            query: Search query\n            context_chars: Characters of context on each side\n            \n        Returns:\n            Snippet with query highlighted\n        \"\"\"\n        content_lower = content.lower()\n        index = content_lower.find(query)\n        \n        if index == -1:\n            return \"\"\n        \n        start = max(0, index - context_chars)\n        end = min(len(content), index + len(query) + context_chars)\n        \n        snippet = content[start:end]\n        if start > 0:\n            snippet = \"...\" + snippet\n        if end < len(content):\n            snippet = snippet + \"...\"\n            \n        return snippet\n    \n    async def cleanup_old_sessions(self, days: int = 30):\n        \"\"\"Clean up sessions older than specified days.\n        \n        Args:\n            days: Number of days to keep sessions\n        \"\"\"\n        from datetime import timedelta\n        \n        cutoff_date = datetime.now() - timedelta(days=days)\n        removed_count = 0\n        \n        for session_id, info in list(self.metadata.get(\"sessions\", {}).items()):\n            try:\n                saved_at = datetime.fromisoformat(info.get(\"saved_at\", \"\"))\n                if saved_at < cutoff_date:\n                    # Remove session file\n                    session_file = Path(info.get(\"path\", \"\"))\n                    if session_file.exists():\n                        session_file.unlink()\n                    \n                    # Remove from metadata\n                    del self.metadata[\"sessions\"][session_id]\n                    removed_count += 1\n                    \n            except Exception as e:\n                logger.error(f\"Error cleaning up session {session_id}: {e}\")\n        \n        if removed_count > 0:\n            await self.save_metadata()\n            logger.info(f\"Cleaned up {removed_count} old sessions\")\n    \n    def get_storage_stats(self) -> Dict[str, Any]:\n        \"\"\"Get storage statistics.\n        \n        Returns:\n            Dictionary with storage stats\n        \"\"\"\n        total_size = 0\n        file_count = 0\n        \n        for path in [self.sessions_path, self.responses_path, self.baselines_path]:\n            for file_path in path.glob(\"*\"):\n                if file_path.is_file():\n                    total_size += file_path.stat().st_size\n                    file_count += 1\n        \n        return {\n            \"total_sessions\": self.metadata.get(\"total_sessions\", 0),\n            \"total_responses\": self.metadata.get(\"total_responses\", 0),\n            \"total_files\": file_count,\n            \"total_size_bytes\": total_size,\n            \"total_size_mb\": round(total_size / (1024 * 1024), 2)\n        }\n\n--- File: lib/context_analyzer.py ---\n\"\"\"\nContext Analyzer - Intelligent context detection with NLP enhancement.\n\"\"\"\n\nimport os\nimport re\nimport asyncio\nimport aiofiles\nfrom pathlib import Path\nfrom typing import List, Dict, Any, Optional, Tuple\nfrom dataclasses import dataclass\nimport logging\nimport json\nfrom collections import Counter\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass ContextItem:\n    \"\"\"Represents a piece of context.\"\"\"\n    path: str\n    content: str\n    relevance_score: float\n    token_estimate: int\n    type: str  # file, snippet, documentation, etc.\n    metadata: Dict[str, Any]\n    \n    def to_dict(self) -> Dict[str, Any]:\n        return {\n            \"path\": self.path,\n            \"relevance_score\": self.relevance_score,\n            \"token_estimate\": self.token_estimate,\n            \"type\": self.type,\n            \"metadata\": self.metadata,\n            \"content_preview\": self.content[:200] + \"...\" if len(self.content) > 200 else self.content\n        }\n\n\nclass ContextAnalyzer:\n    \"\"\"Analyzes questions and gathers intelligent context.\"\"\"\n    \n    def __init__(self, project_root: Optional[Path] = None, token_budget: int = 10000):\n        \"\"\"Initialize context analyzer.\n        \n        Args:\n            project_root: Root directory of the project\n            token_budget: Maximum tokens for context\n        \"\"\"\n        self.project_root = project_root or Path.cwd()\n        self.token_budget = token_budget\n        \n        # Question type patterns\n        self.question_patterns = {\n            \"implementation\": [\n                r\"how (do|can|should) (i|we)\",\n                r\"implement\",\n                r\"create\",\n                r\"build\",\n                r\"add\",\n                r\"develop\"\n            ],\n            \"debugging\": [\n                r\"error\",\n                r\"bug\",\n                r\"fix\",\n                r\"issue\",\n                r\"problem\",\n                r\"not working\",\n                r\"fails?\",\n                r\"crash\",\n                r\"exception\"\n            ],\n            \"optimization\": [\n                r\"optimi[zs]e\",\n                r\"improve\",\n                r\"faster\",\n                r\"better\",\n                r\"performance\",\n                r\"efficient\",\n                r\"reduce\",\n                r\"speed up\"\n            ],\n            \"explanation\": [\n                r\"what (is|are|does)\",\n                r\"explain\",\n                r\"understand\",\n                r\"why\",\n                r\"how does\",\n                r\"describe\"\n            ],\n            \"testing\": [\n                r\"test\",\n                r\"verify\",\n                r\"validate\",\n                r\"check\",\n                r\"assert\",\n                r\"mock\"\n            ]\n        }\n        \n        # File type associations\n        self.file_associations = {\n            \"python\": [\".py\", \".pyi\"],\n            \"javascript\": [\".js\", \".jsx\", \".ts\", \".tsx\"],\n            \"config\": [\".json\", \".yaml\", \".yml\", \".toml\", \".ini\"],\n            \"documentation\": [\".md\", \".rst\", \".txt\"],\n            \"web\": [\".html\", \".css\", \".scss\"]\n        }\n    \n    async def analyze_question(self, question: str) -> Dict[str, Any]:\n        \"\"\"Analyze a question to determine type and extract key information.\n        \n        Args:\n            question: User's question\n            \n        Returns:\n            Analysis results including type, keywords, entities\n        \"\"\"\n        analysis = {\n            \"question\": question,\n            \"type\": self._detect_question_type(question),\n            \"keywords\": self._extract_keywords(question),\n            \"entities\": self._extract_entities(question),\n            \"file_references\": self._extract_file_references(question),\n            \"requires_code\": self._requires_code_context(question)\n        }\n        \n        logger.debug(f\"Question analysis: {analysis}\")\n        return analysis\n    \n    def _detect_question_type(self, question: str) -> str:\n        \"\"\"Detect the type of question.\n        \n        Args:\n            question: User's question\n            \n        Returns:\n            Question type\n        \"\"\"\n        question_lower = question.lower()\n        scores = {}\n        \n        for q_type, patterns in self.question_patterns.items():\n            score = 0\n            for pattern in patterns:\n                if re.search(pattern, question_lower):\n                    score += 1\n            scores[q_type] = score\n        \n        # Return type with highest score, default to \"general\"\n        if scores:\n            return max(scores, key=scores.get)\n        return \"general\"\n    \n    def _extract_keywords(self, question: str) -> List[str]:\n        \"\"\"Extract important keywords from the question.\n        \n        Args:\n            question: User's question\n            \n        Returns:\n            List of keywords\n        \"\"\"\n        # Remove common words\n        stop_words = {\n            \"the\", \"a\", \"an\", \"and\", \"or\", \"but\", \"in\", \"on\", \"at\", \"to\", \"for\",\n            \"of\", \"with\", \"by\", \"from\", \"as\", \"is\", \"was\", \"are\", \"were\", \"been\",\n            \"be\", \"have\", \"has\", \"had\", \"do\", \"does\", \"did\", \"will\", \"would\",\n            \"could\", \"should\", \"may\", \"might\", \"must\", \"can\", \"shall\", \"need\"\n        }\n        \n        # Tokenize and filter\n        words = re.findall(r'\\b[a-zA-Z_][a-zA-Z0-9_]*\\b', question.lower())\n        keywords = [w for w in words if w not in stop_words and len(w) > 2]\n        \n        # Count frequency and return top keywords\n        word_freq = Counter(keywords)\n        return [word for word, _ in word_freq.most_common(10)]\n    \n    def _extract_entities(self, question: str) -> Dict[str, List[str]]:\n        \"\"\"Extract entities like function names, classes, files.\n        \n        Args:\n            question: User's question\n            \n        Returns:\n            Dictionary of entity types and values\n        \"\"\"\n        entities = {\n            \"functions\": [],\n            \"classes\": [],\n            \"files\": [],\n            \"modules\": []\n        }\n        \n        # Function/method patterns (camelCase or snake_case followed by parentheses)\n        func_pattern = r'\\b([a-z_][a-zA-Z0-9_]*|[a-z][a-zA-Z0-9]*)\\s*\\('\n        entities[\"functions\"] = re.findall(func_pattern, question)\n        \n        # Class patterns (PascalCase)\n        class_pattern = r'\\b([A-Z][a-zA-Z0-9]+)\\b'\n        entities[\"classes\"] = re.findall(class_pattern, question)\n        \n        # File patterns\n        file_pattern = r'([a-zA-Z0-9_\\-]+\\.[a-zA-Z0-9]+)'\n        entities[\"files\"] = re.findall(file_pattern, question)\n        \n        # Module/package patterns (dot notation)\n        module_pattern = r'\\b([a-z_][a-z0-9_]*(?:\\.[a-z_][a-z0-9_]*)+)\\b'\n        entities[\"modules\"] = re.findall(module_pattern, question)\n        \n        return entities\n    \n    def _extract_file_references(self, question: str) -> List[str]:\n        \"\"\"Extract file paths or names mentioned in the question.\n        \n        Args:\n            question: User's question\n            \n        Returns:\n            List of file references\n        \"\"\"\n        files = []\n        \n        # Direct file paths\n        path_pattern = r'(?:[.\\/\\\\])?(?:[a-zA-Z0-9_\\-]+[\\/\\\\])*[a-zA-Z0-9_\\-]+\\.[a-zA-Z0-9]+'\n        files.extend(re.findall(path_pattern, question))\n        \n        # File names without extension but with common prefixes\n        name_pattern = r'\\b(test_|spec_|config|settings|main|index|app)\\w*\\b'\n        potential_files = re.findall(name_pattern, question, re.IGNORECASE)\n        files.extend(potential_files)\n        \n        return list(set(files))\n    \n    def _requires_code_context(self, question: str) -> bool:\n        \"\"\"Determine if the question requires code context.\n        \n        Args:\n            question: User's question\n            \n        Returns:\n            True if code context is likely needed\n        \"\"\"\n        code_indicators = [\n            \"function\", \"method\", \"class\", \"variable\", \"parameter\",\n            \"implement\", \"code\", \"syntax\", \"error\", \"bug\", \"line\",\n            \"import\", \"module\", \"package\", \"library\", \"api\"\n        ]\n        \n        question_lower = question.lower()\n        return any(indicator in question_lower for indicator in code_indicators)\n    \n    async def gather_context(\n        self,\n        analysis: Dict[str, Any],\n        include_files: Optional[List[str]] = None\n    ) -> List[ContextItem]:\n        \"\"\"Gather relevant context based on analysis.\n        \n        Args:\n            analysis: Question analysis results\n            include_files: Specific files to include\n            \n        Returns:\n            List of context items within token budget\n        \"\"\"\n        context_items = []\n        \n        # 1. Add specifically requested files\n        if include_files:\n            for file_path in include_files:\n                item = await self._load_file_context(file_path)\n                if item:\n                    context_items.append(item)\n        \n        # 2. Find files based on entities\n        entities = analysis.get(\"entities\", {})\n        for file_ref in entities.get(\"files\", []):\n            files = await self._find_files_by_name(file_ref)\n            for file_path in files[:3]:  # Limit to top 3 matches\n                item = await self._load_file_context(file_path)\n                if item:\n                    context_items.append(item)\n        \n        # 3. Find files based on keywords\n        keywords = analysis.get(\"keywords\", [])\n        relevant_files = await self._find_relevant_files(keywords, analysis.get(\"type\", \"general\"))\n        for file_path in relevant_files[:5]:  # Top 5 relevant files\n            item = await self._load_file_context(file_path)\n            if item:\n                context_items.append(item)\n        \n        # 4. Add configuration files if needed\n        if analysis.get(\"type\") in [\"implementation\", \"debugging\"]:\n            config_files = await self._find_config_files()\n            for file_path in config_files[:2]:\n                item = await self._load_file_context(file_path)\n                if item:\n                    context_items.append(item)\n        \n        # 5. Score and prioritize context items\n        scored_items = self._score_context_items(context_items, analysis)\n        \n        # 6. Fit within token budget\n        final_context = self._fit_token_budget(scored_items)\n        \n        return final_context\n    \n    async def _load_file_context(self, file_path: str) -> Optional[ContextItem]:\n        \"\"\"Load a file as a context item.\n        \n        Args:\n            file_path: Path to the file\n            \n        Returns:\n            ContextItem or None if file cannot be loaded\n        \"\"\"\n        full_path = self.project_root / file_path\n        \n        if not full_path.exists() or not full_path.is_file():\n            return None\n        \n        try:\n            async with aiofiles.open(full_path, 'r') as f:\n                content = await f.read()\n            \n            # Skip very large files\n            if len(content) > 50000:\n                content = content[:50000] + \"\\n... (truncated)\"\n            \n            return ContextItem(\n                path=str(file_path),\n                content=content,\n                relevance_score=0.5,  # Default score, will be updated\n                token_estimate=len(content) // 4,\n                type=\"file\",\n                metadata={\n                    \"size\": len(content),\n                    \"extension\": full_path.suffix\n                }\n            )\n            \n        except Exception as e:\n            logger.error(f\"Failed to load file {file_path}: {e}\")\n            return None\n    \n    async def _find_files_by_name(self, name_pattern: str) -> List[str]:\n        \"\"\"Find files matching a name pattern.\n        \n        Args:\n            name_pattern: File name or pattern to search\n            \n        Returns:\n            List of file paths\n        \"\"\"\n        matches = []\n        \n        # Walk through project directory\n        for root, dirs, files in os.walk(self.project_root):\n            # Skip hidden directories and common ignore patterns\n            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['node_modules', '__pycache__', 'venv']]\n            \n            for file in files:\n                if name_pattern.lower() in file.lower():\n                    rel_path = Path(root) / file\n                    matches.append(str(rel_path.relative_to(self.project_root)))\n        \n        return matches[:10]  # Limit results\n    \n    async def _find_relevant_files(self, keywords: List[str], question_type: str) -> List[str]:\n        \"\"\"Find files relevant to keywords and question type.\n        \n        Args:\n            keywords: List of keywords\n            question_type: Type of question\n            \n        Returns:\n            List of relevant file paths\n        \"\"\"\n        relevant_files = []\n        file_scores = {}\n        \n        # Determine preferred file types based on question type\n        if question_type == \"testing\":\n            preferred_patterns = [\"test_\", \"_test\", \"spec_\", \"_spec\"]\n        elif question_type == \"implementation\":\n            preferred_patterns = [\"lib/\", \"src/\", \"core/\"]\n        elif question_type == \"configuration\":\n            preferred_patterns = [\"config\", \"settings\", \".env\", \".json\", \".yaml\"]\n        else:\n            preferred_patterns = []\n        \n        # Walk through project\n        for root, dirs, files in os.walk(self.project_root):\n            # Skip ignored directories\n            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['node_modules', '__pycache__', 'venv']]\n            \n            for file in files:\n                # Skip non-text files\n                if not any(file.endswith(ext) for ext in ['.py', '.js', '.ts', '.json', '.yaml', '.md', '.txt']):\n                    continue\n                \n                rel_path = Path(root) / file\n                file_path = str(rel_path.relative_to(self.project_root))\n                \n                # Calculate relevance score\n                score = 0\n                \n                # Check for keyword matches in filename\n                for keyword in keywords:\n                    if keyword.lower() in file.lower():\n                        score += 2\n                    if keyword.lower() in file_path.lower():\n                        score += 1\n                \n                # Boost for preferred patterns\n                for pattern in preferred_patterns:\n                    if pattern in file_path.lower():\n                        score += 3\n                \n                if score > 0:\n                    file_scores[file_path] = score\n        \n        # Sort by score and return top files\n        sorted_files = sorted(file_scores.items(), key=lambda x: x[1], reverse=True)\n        return [f[0] for f in sorted_files[:10]]\n    \n    async def _find_config_files(self) -> List[str]:\n        \"\"\"Find configuration files in the project.\n        \n        Returns:\n            List of configuration file paths\n        \"\"\"\n        config_files = []\n        config_patterns = [\n            \"pyproject.toml\", \"package.json\", \"requirements.txt\",\n            \".env\", \".env.example\", \"config.json\", \"config.yaml\",\n            \"settings.py\", \"config.py\", \"setup.py\"\n        ]\n        \n        for pattern in config_patterns:\n            file_path = self.project_root / pattern\n            if file_path.exists():\n                config_files.append(pattern)\n        \n        return config_files\n    \n    def _score_context_items(\n        self,\n        items: List[ContextItem],\n        analysis: Dict[str, Any]\n    ) -> List[ContextItem]:\n        \"\"\"Score and sort context items by relevance.\n        \n        Args:\n            items: List of context items\n            analysis: Question analysis\n            \n        Returns:\n            Sorted list of context items\n        \"\"\"\n        keywords = analysis.get(\"keywords\", [])\n        entities = analysis.get(\"entities\", {})\n        \n        for item in items:\n            score = item.relevance_score\n            \n            # Score based on keyword matches in content\n            content_lower = item.content.lower()\n            for keyword in keywords:\n                if keyword.lower() in content_lower:\n                    # Count occurrences (up to 5)\n                    count = min(content_lower.count(keyword.lower()), 5)\n                    score += count * 0.1\n            \n            # Score based on entity matches\n            for entity_list in entities.values():\n                for entity in entity_list:\n                    if entity in item.content:\n                        score += 0.3\n            \n            # Penalty for very large files\n            if item.token_estimate > 2000:\n                score *= 0.7\n            \n            item.relevance_score = min(score, 1.0)\n        \n        # Sort by relevance score\n        return sorted(items, key=lambda x: x.relevance_score, reverse=True)\n    \n    def _fit_token_budget(self, items: List[ContextItem]) -> List[ContextItem]:\n        \"\"\"Fit context items within token budget.\n        \n        Args:\n            items: Sorted list of context items\n            \n        Returns:\n            List of items that fit within budget\n        \"\"\"\n        selected = []\n        total_tokens = 0\n        \n        for item in items:\n            if total_tokens + item.token_estimate <= self.token_budget:\n                selected.append(item)\n                total_tokens += item.token_estimate\n            else:\n                # Try to add a truncated version\n                remaining_tokens = self.token_budget - total_tokens\n                if remaining_tokens > 500:  # Only if meaningful content can be added\n                    # Truncate content to fit\n                    truncated_content = item.content[:remaining_tokens * 4]\n                    item.content = truncated_content + \"\\n... (truncated to fit token budget)\"\n                    item.token_estimate = remaining_tokens\n                    selected.append(item)\n                break\n        \n        logger.info(f\"Selected {len(selected)} context items, total tokens: {total_tokens}\")\n        return selected\n    \n    def estimate_tokens(self, text: str) -> int:\n        \"\"\"Estimate token count for text.\n        \n        Args:\n            text: Text to estimate\n            \n        Returns:\n            Estimated token count\n        \"\"\"\n        # Rough estimate: 1 token per 4 characters\n        return len(text) // 4\n\n--- File: lib/baseline_generator.py ---\n\"\"\"\nBaseline Generator - Creates structured baseline documents for complex discussions.\n\"\"\"\n\nfrom typing import List, Dict, Any, Optional\nfrom datetime import datetime\nfrom dataclasses import dataclass\nimport logging\n\nfrom .context_analyzer import ContextItem\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass BaselineSection:\n    \"\"\"Represents a section of the baseline document.\"\"\"\n    title: str\n    content: str\n    priority: int = 1  # 1=highest, 5=lowest\n    token_estimate: int = 0\n    \n    def __post_init__(self):\n        if self.token_estimate == 0:\n            self.token_estimate = len(self.content) // 4\n\n\nclass BaselineGenerator:\n    \"\"\"Generates structured baseline documents for Grok discussions.\"\"\"\n    \n    def __init__(self, token_budget: int = 10000):\n        \"\"\"Initialize baseline generator.\n        \n        Args:\n            token_budget: Maximum tokens for baseline document\n        \"\"\"\n        self.token_budget = token_budget\n        \n    async def generate(\n        self,\n        topic: str,\n        analysis: Dict[str, Any],\n        context_items: List[ContextItem],\n        use_expert_mode: bool = False\n    ) -> str:\n        \"\"\"Generate a comprehensive baseline document.\n        \n        Args:\n            topic: Discussion topic\n            analysis: Question analysis results\n            context_items: Gathered context items\n            use_expert_mode: Whether to include expert perspectives\n            \n        Returns:\n            Formatted baseline document\n        \"\"\"\n        logger.info(f\"Generating baseline document for topic: {topic}\")\n        \n        sections = []\n        \n        # 1. Executive Summary\n        sections.append(BaselineSection(\n            title=\"Executive Summary\",\n            content=self._create_executive_summary(topic, analysis),\n            priority=1\n        ))\n        \n        # 2. Problem Analysis\n        sections.append(BaselineSection(\n            title=\"Problem Analysis\",\n            content=self._analyze_problem(topic, analysis),\n            priority=1\n        ))\n        \n        # 3. Current Context\n        if context_items:\n            sections.append(BaselineSection(\n                title=\"Current Implementation Context\",\n                content=self._summarize_context(context_items),\n                priority=2\n            ))\n        \n        # 4. Technical Requirements\n        sections.append(BaselineSection(\n            title=\"Technical Requirements\",\n            content=self._extract_requirements(topic, analysis),\n            priority=2\n        ))\n        \n        # 5. Expert Perspectives (if enabled)\n        if use_expert_mode:\n            sections.append(BaselineSection(\n                title=\"Expert Perspectives\",\n                content=self._gather_expert_perspectives(topic, analysis),\n                priority=3\n            ))\n        \n        # 6. Proposed Approach\n        sections.append(BaselineSection(\n            title=\"Proposed Approach\",\n            content=self._suggest_approach(topic, analysis),\n            priority=2\n        ))\n        \n        # 7. Key Questions\n        sections.append(BaselineSection(\n            title=\"Key Questions for Discussion\",\n            content=self._generate_questions(topic, analysis),\n            priority=1\n        ))\n        \n        # 8. Success Criteria\n        sections.append(BaselineSection(\n            title=\"Success Criteria\",\n            content=self._define_success_criteria(topic, analysis),\n            priority=2\n        ))\n        \n        # Assemble document within token budget\n        return self._assemble_document(sections, topic)\n    \n    def _create_executive_summary(self, topic: str, analysis: Dict[str, Any]) -> str:\n        \"\"\"Create an executive summary of the discussion topic.\n        \n        Args:\n            topic: Discussion topic\n            analysis: Question analysis\n            \n        Returns:\n            Executive summary content\n        \"\"\"\n        question_type = analysis.get(\"type\", \"general\")\n        keywords = analysis.get(\"keywords\", [])\n        \n        summary = f\"\"\"This document analyzes the following topic:\n**\"{topic}\"**\n\n**Generated**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n**Question Type**: {question_type.capitalize()}\n**Key Focus Areas**: {', '.join(keywords[:5]) if keywords else 'General discussion'}\n\n**Purpose**: This baseline document provides a structured foundation for an informed discussion \nwith Grok-4, ensuring all relevant context and considerations are captured.\"\"\"\n        \n        return summary\n    \n    def _analyze_problem(self, topic: str, analysis: Dict[str, Any]) -> str:\n        \"\"\"Analyze the problem or topic in detail.\n        \n        Args:\n            topic: Discussion topic\n            analysis: Question analysis\n            \n        Returns:\n            Problem analysis content\n        \"\"\"\n        question_type = analysis.get(\"type\", \"general\")\n        entities = analysis.get(\"entities\", {})\n        \n        content = f\"\"\"## Problem Statement\n{topic}\n\n## Analysis Type\nThis appears to be a **{question_type}** question.\"\"\"\n        \n        if question_type == \"implementation\":\n            content += \"\"\"\n\n### Implementation Considerations\n- **Scope**: What components need to be created or modified?\n- **Dependencies**: What existing systems will this interact with?\n- **Constraints**: What limitations or requirements must be met?\n- **Performance**: What performance characteristics are expected?\"\"\"\n        \n        elif question_type == \"debugging\":\n            content += \"\"\"\n\n### Debugging Approach\n- **Symptoms**: What specific errors or unexpected behaviors are occurring?\n- **Reproduction**: Can the issue be consistently reproduced?\n- **Impact**: What functionality is affected?\n- **Timeline**: When did the issue first appear?\"\"\"\n        \n        elif question_type == \"optimization\":\n            content += \"\"\"\n\n### Optimization Goals\n- **Current Performance**: What are the current metrics?\n- **Target Performance**: What improvements are needed?\n- **Bottlenecks**: What are the likely performance bottlenecks?\n- **Trade-offs**: What trade-offs are acceptable?\"\"\"\n        \n        # Add entity information if present\n        if any(entities.values()):\n            content += \"\\n\\n### Identified Components\"\n            if entities.get(\"functions\"):\n                content += f\"\\n- **Functions**: {', '.join(entities['functions'])}\"\n            if entities.get(\"classes\"):\n                content += f\"\\n- **Classes**: {', '.join(entities['classes'])}\"\n            if entities.get(\"files\"):\n                content += f\"\\n- **Files**: {', '.join(entities['files'])}\"\n            if entities.get(\"modules\"):\n                content += f\"\\n- **Modules**: {', '.join(entities['modules'])}\"\n        \n        return content\n    \n    def _summarize_context(self, context_items: List[ContextItem]) -> str:\n        \"\"\"Summarize the gathered context.\n        \n        Args:\n            context_items: List of context items\n            \n        Returns:\n            Context summary\n        \"\"\"\n        content = \"## Available Context\\n\\n\"\n        content += f\"**Total Context Items**: {len(context_items)}\\n\"\n        content += f\"**Estimated Tokens**: {sum(item.token_estimate for item in context_items)}\\n\\n\"\n        \n        # Group by type\n        by_type = {}\n        for item in context_items:\n            if item.type not in by_type:\n                by_type[item.type] = []\n            by_type[item.type].append(item)\n        \n        for item_type, items in by_type.items():\n            content += f\"\\n### {item_type.capitalize()} Context ({len(items)} items)\\n\"\n            for item in items[:5]:  # Show top 5 per type\n                content += f\"- **{item.path}** (relevance: {item.relevance_score:.2f})\\n\"\n                \n                # Add brief preview if available\n                if item.metadata.get(\"extension\") in [\".py\", \".js\", \".ts\"]:\n                    # Extract first function or class if possible\n                    lines = item.content.split('\\n')[:10]\n                    preview = '\\n'.join(lines[:3])\n                    if len(preview) > 100:\n                        preview = preview[:100] + \"...\"\n                    content += f\"  ```\\n  {preview}\\n  ```\\n\"\n        \n        return content\n    \n    def _extract_requirements(self, topic: str, analysis: Dict[str, Any]) -> str:\n        \"\"\"Extract technical requirements from the topic.\n        \n        Args:\n            topic: Discussion topic\n            analysis: Question analysis\n            \n        Returns:\n            Requirements content\n        \"\"\"\n        question_type = analysis.get(\"type\", \"general\")\n        \n        content = \"## Technical Requirements\\n\\n\"\n        \n        if question_type == \"implementation\":\n            content += \"\"\"### Functional Requirements\n- Primary functionality to be implemented\n- User interactions and workflows\n- Data inputs and outputs\n- Integration points\n\n### Non-Functional Requirements\n- Performance expectations\n- Security considerations\n- Scalability needs\n- Maintainability standards\"\"\"\n        \n        elif question_type == \"debugging\":\n            content += \"\"\"### Debugging Requirements\n- Error messages and stack traces\n- System state when error occurs\n- Expected vs actual behavior\n- Test cases to verify fix\"\"\"\n        \n        elif question_type == \"optimization\":\n            content += \"\"\"### Performance Requirements\n- Current performance metrics\n- Target performance goals\n- Acceptable resource usage\n- Response time requirements\"\"\"\n        \n        else:\n            content += \"\"\"### General Requirements\n- Clear problem definition\n- Desired outcome\n- Constraints and limitations\n- Success metrics\"\"\"\n        \n        return content\n    \n    def _gather_expert_perspectives(self, topic: str, analysis: Dict[str, Any]) -> str:\n        \"\"\"Gather multiple expert perspectives on the topic.\n        \n        Args:\n            topic: Discussion topic\n            analysis: Question analysis\n            \n        Returns:\n            Expert perspectives content\n        \"\"\"\n        question_type = analysis.get(\"type\", \"general\")\n        \n        content = \"## Expert Perspectives\\n\\n\"\n        \n        # Software Architect perspective\n        content += \"\"\"### Software Architect Perspective\n- **Architecture Impact**: How does this affect system architecture?\n- **Design Patterns**: What patterns could be applied?\n- **Scalability**: How will this scale with growth?\n- **Maintainability**: How can we ensure long-term maintainability?\n\n\"\"\"\n        \n        # Security Expert perspective\n        content += \"\"\"### Security Expert Perspective\n- **Security Risks**: What security vulnerabilities might this introduce?\n- **Data Protection**: How is sensitive data handled?\n- **Access Control**: What authorization is needed?\n- **Audit Trail**: What needs to be logged for security?\n\n\"\"\"\n        \n        # Performance Engineer perspective\n        if question_type in [\"implementation\", \"optimization\"]:\n            content += \"\"\"### Performance Engineer Perspective\n- **Performance Impact**: What is the performance cost?\n- **Optimization Opportunities**: Where can we optimize?\n- **Caching Strategy**: What can be cached?\n- **Resource Usage**: What resources are consumed?\n\n\"\"\"\n        \n        # QA Engineer perspective\n        content += \"\"\"### QA Engineer Perspective\n- **Testing Strategy**: How will this be tested?\n- **Edge Cases**: What edge cases need consideration?\n- **Test Coverage**: What coverage is needed?\n- **Regression Risk**: What existing functionality might be affected?\"\"\"\n        \n        return content\n    \n    def _suggest_approach(self, topic: str, analysis: Dict[str, Any]) -> str:\n        \"\"\"Suggest an approach to addressing the topic.\n        \n        Args:\n            topic: Discussion topic\n            analysis: Question analysis\n            \n        Returns:\n            Suggested approach content\n        \"\"\"\n        question_type = analysis.get(\"type\", \"general\")\n        \n        content = \"## Proposed Approach\\n\\n\"\n        \n        if question_type == \"implementation\":\n            content += \"\"\"### Implementation Strategy\n1. **Planning Phase**\n   - Define clear requirements\n   - Design component interfaces\n   - Identify dependencies\n\n2. **Development Phase**\n   - Implement core functionality\n   - Write unit tests\n   - Handle error cases\n\n3. **Testing Phase**\n   - Run unit tests\n   - Perform integration testing\n   - Validate edge cases\n\n4. **Deployment Phase**\n   - Code review\n   - Documentation update\n   - Deployment preparation\"\"\"\n        \n        elif question_type == \"debugging\":\n            content += \"\"\"### Debugging Strategy\n1. **Reproduce the Issue**\n   - Identify steps to reproduce\n   - Isolate the problem area\n   - Gather error information\n\n2. **Root Cause Analysis**\n   - Analyze stack traces\n   - Check recent changes\n   - Review related components\n\n3. **Develop Fix**\n   - Implement targeted solution\n   - Add defensive coding\n   - Include error handling\n\n4. **Verify Solution**\n   - Test the fix\n   - Check for regressions\n   - Validate edge cases\"\"\"\n        \n        elif question_type == \"optimization\":\n            content += \"\"\"### Optimization Strategy\n1. **Measure Current State**\n   - Profile performance\n   - Identify bottlenecks\n   - Establish baseline metrics\n\n2. **Analyze Opportunities**\n   - Algorithm improvements\n   - Caching possibilities\n   - Resource optimization\n\n3. **Implement Improvements**\n   - Apply optimizations\n   - Maintain functionality\n   - Add performance tests\n\n4. **Validate Results**\n   - Measure improvements\n   - Compare to targets\n   - Check for side effects\"\"\"\n        \n        else:\n            content += \"\"\"### General Approach\n1. **Analysis**\n   - Understand the problem\n   - Gather requirements\n   - Research solutions\n\n2. **Design**\n   - Plan the solution\n   - Consider alternatives\n   - Choose best approach\n\n3. **Implementation**\n   - Build the solution\n   - Test thoroughly\n   - Document clearly\n\n4. **Validation**\n   - Verify requirements met\n   - Get feedback\n   - Iterate if needed\"\"\"\n        \n        return content\n    \n    def _generate_questions(self, topic: str, analysis: Dict[str, Any]) -> str:\n        \"\"\"Generate key questions for the discussion.\n        \n        Args:\n            topic: Discussion topic\n            analysis: Question analysis\n            \n        Returns:\n            Questions content\n        \"\"\"\n        question_type = analysis.get(\"type\", \"general\")\n        keywords = analysis.get(\"keywords\", [])\n        \n        content = \"## Key Questions for Discussion\\n\\n\"\n        \n        # Type-specific questions\n        if question_type == \"implementation\":\n            content += \"\"\"### Implementation Questions\n1. What is the best architectural pattern for this implementation?\n2. How should error handling be structured?\n3. What external dependencies are acceptable?\n4. How can we ensure the code is testable and maintainable?\n5. What performance considerations should be addressed upfront?\n\n\"\"\"\n        elif question_type == \"debugging\":\n            content += \"\"\"### Debugging Questions\n1. What is the exact error message and stack trace?\n2. When did this issue first appear?\n3. What recent changes might have caused this?\n4. Can this be reproduced consistently?\n5. What is the impact on users or system functionality?\n\n\"\"\"\n        elif question_type == \"optimization\":\n            content += \"\"\"### Optimization Questions\n1. What are the current performance metrics?\n2. What is the target performance goal?\n3. Which operations are the bottlenecks?\n4. What trade-offs are acceptable?\n5. How will we measure success?\n\n\"\"\"\n        \n        # General questions\n        content += \"\"\"### General Considerations\n1. What are the main risks or challenges?\n2. Are there existing solutions or patterns to consider?\n3. What is the timeline for this work?\n4. Who are the stakeholders?\n5. What documentation is needed?\"\"\"\n        \n        # Add keyword-specific questions if relevant\n        if keywords:\n            content += f\"\\n\\n### Topic-Specific Questions\\n\"\n            for i, keyword in enumerate(keywords[:3], 1):\n                content += f\"{i}. How does this relate to {keyword}?\\n\"\n        \n        return content\n    \n    def _define_success_criteria(self, topic: str, analysis: Dict[str, Any]) -> str:\n        \"\"\"Define success criteria for the discussion.\n        \n        Args:\n            topic: Discussion topic\n            analysis: Question analysis\n            \n        Returns:\n            Success criteria content\n        \"\"\"\n        question_type = analysis.get(\"type\", \"general\")\n        \n        content = \"## Success Criteria\\n\\n\"\n        \n        content += \"### Primary Success Metrics\\n\"\n        \n        if question_type == \"implementation\":\n            content += \"\"\"- [ ] Feature is fully implemented and working\n- [ ] All unit tests pass\n- [ ] Code is reviewed and approved\n- [ ] Documentation is updated\n- [ ] No regression in existing functionality\"\"\"\n        \n        elif question_type == \"debugging\":\n            content += \"\"\"- [ ] Bug is identified and fixed\n- [ ] Root cause is understood\n- [ ] Fix is tested and verified\n- [ ] No new issues introduced\n- [ ] Prevention measures documented\"\"\"\n        \n        elif question_type == \"optimization\":\n            content += \"\"\"- [ ] Performance targets are met\n- [ ] No functionality is broken\n- [ ] Improvements are measurable\n- [ ] Resource usage is acceptable\n- [ ] Solution is sustainable\"\"\"\n        \n        else:\n            content += \"\"\"- [ ] Problem is clearly understood\n- [ ] Solution is well-designed\n- [ ] Implementation is complete\n- [ ] Quality standards are met\n- [ ] Stakeholders are satisfied\"\"\"\n        \n        content += \"\"\"\n\n### Secondary Success Indicators\n- Clear understanding of trade-offs\n- Knowledge transfer completed\n- Future improvements identified\n- Lessons learned documented\n- Team alignment achieved\"\"\"\n        \n        return content\n    \n    def _assemble_document(self, sections: List[BaselineSection], topic: str) -> str:\n        \"\"\"Assemble the final baseline document within token budget.\n        \n        Args:\n            sections: List of document sections\n            topic: Discussion topic\n            \n        Returns:\n            Assembled baseline document\n        \"\"\"\n        # Sort sections by priority\n        sections.sort(key=lambda x: x.priority)\n        \n        # Start with header\n        document = f\"# Baseline Document\\n\\n\"\n        document += f\"**Topic**: {topic}\\n\"\n        document += f\"**Generated**: {datetime.now().isoformat()}\\n\"\n        document += f\"**Document Version**: 1.0.0\\n\\n\"\n        document += \"---\\n\\n\"\n        \n        # Calculate header tokens\n        used_tokens = len(document) // 4\n        \n        # Add sections within budget\n        for section in sections:\n            if used_tokens + section.token_estimate <= self.token_budget:\n                document += f\"## {section.title}\\n\\n\"\n                document += section.content\n                document += \"\\n\\n\"\n                used_tokens += section.token_estimate\n            else:\n                # Try to add truncated version\n                remaining_tokens = self.token_budget - used_tokens\n                if remaining_tokens > 200:\n                    truncated = section.content[:remaining_tokens * 4]\n                    document += f\"## {section.title}\\n\\n\"\n                    document += truncated\n                    document += \"\\n... (section truncated to fit token budget)\\n\\n\"\n                    break\n        \n        # Add footer\n        document += \"---\\n\\n\"\n        document += f\"*Document contains approximately {used_tokens} tokens*\\n\"\n        \n        logger.info(f\"Generated baseline document with {used_tokens} tokens\")\n        return document\n\n--- File: lib/grok_client.py ---\n\"\"\"\nGrok Client - X.AI API wrapper with streaming and retry logic.\n\"\"\"\n\nimport asyncio\nimport os\nimport time\nfrom typing import Optional, List, Dict, Any, AsyncGenerator\nfrom dataclasses import dataclass\nimport json\nimport logging\n\nfrom openai import AsyncOpenAI\nfrom openai.types.chat import ChatCompletionMessageParam\nimport openai\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass GrokResponse:\n    \"\"\"Represents a response from Grok API.\"\"\"\n    content: str\n    tokens_used: int\n    model: str\n    timestamp: float\n    streaming: bool = False\n    \n    def to_dict(self) -> Dict[str, Any]:\n        return {\n            \"content\": self.content,\n            \"tokens_used\": self.tokens_used,\n            \"model\": self.model,\n            \"timestamp\": self.timestamp,\n            \"streaming\": self.streaming\n        }\n\n\nclass GrokClient:\n    \"\"\"Client for interacting with X.AI's Grok API.\"\"\"\n    \n    def __init__(\n        self,\n        api_key: Optional[str] = None,\n        model: str = \"grok-4-fast-reasoning\",\n        temperature: float = 0.7,\n        max_retries: int = 3,\n        retry_delay: float = 1.0\n    ):\n        \"\"\"Initialize Grok client.\n        \n        Args:\n            api_key: X.AI API key (defaults to env var XAI_API_KEY)\n            model: Model to use (default: grok-4-fast-reasoning)\n            temperature: Sampling temperature (default: 0.7)\n            max_retries: Maximum number of retry attempts\n            retry_delay: Initial delay between retries (exponential backoff)\n        \"\"\"\n        self.api_key = api_key or os.getenv(\"XAI_API_KEY\")\n        if not self.api_key:\n            raise ValueError(\"XAI_API_KEY not found in environment or provided\")\n            \n        self.model = model\n        self.temperature = temperature\n        self.max_retries = max_retries\n        self.retry_delay = retry_delay\n        \n        self.client = AsyncOpenAI(\n            api_key=self.api_key,\n            base_url=\"https://api.x.ai/v1\",\n        )\n        \n        self.total_tokens_used = 0\n        \n    async def ask(\n        self,\n        prompt: str,\n        system_prompt: Optional[str] = None,\n        stream: bool = True,\n        max_tokens: Optional[int] = None\n    ) -> GrokResponse:\n        \"\"\"Send a single question to Grok.\n        \n        Args:\n            prompt: User prompt/question\n            system_prompt: Optional system prompt for context\n            stream: Whether to stream the response\n            max_tokens: Maximum tokens in response\n            \n        Returns:\n            GrokResponse object with content and metadata\n        \"\"\"\n        messages: List[ChatCompletionMessageParam] = []\n        \n        if system_prompt:\n            messages.append({\"role\": \"system\", \"content\": system_prompt})\n        messages.append({\"role\": \"user\", \"content\": prompt})\n        \n        if stream:\n            return await self._stream_completion(messages, max_tokens)\n        else:\n            return await self._complete(messages, max_tokens)\n    \n    async def _complete(\n        self,\n        messages: List[ChatCompletionMessageParam],\n        max_tokens: Optional[int] = None\n    ) -> GrokResponse:\n        \"\"\"Get a non-streaming completion.\"\"\"\n        for attempt in range(self.max_retries):\n            try:\n                completion = await self.client.chat.completions.create(\n                    model=self.model,\n                    messages=messages,\n                    temperature=self.temperature,\n                    max_tokens=max_tokens,\n                    stream=False\n                )\n                \n                content = completion.choices[0].message.content or \"\"\n                tokens = completion.usage.total_tokens if completion.usage else 0\n                self.total_tokens_used += tokens\n                \n                return GrokResponse(\n                    content=content,\n                    tokens_used=tokens,\n                    model=self.model,\n                    timestamp=time.time(),\n                    streaming=False\n                )\n                \n            except openai.RateLimitError as e:\n                wait_time = self.retry_delay * (2 ** attempt)\n                logger.warning(f\"Rate limit hit, waiting {wait_time}s: {e}\")\n                await asyncio.sleep(wait_time)\n                \n            except Exception as e:\n                if attempt == self.max_retries - 1:\n                    logger.error(f\"Failed after {self.max_retries} attempts: {e}\")\n                    raise\n                wait_time = self.retry_delay * (2 ** attempt)\n                logger.warning(f\"Attempt {attempt + 1} failed, retrying in {wait_time}s: {e}\")\n                await asyncio.sleep(wait_time)\n                \n        raise Exception(f\"Failed to get completion after {self.max_retries} attempts\")\n    \n    async def _stream_completion(\n        self,\n        messages: List[ChatCompletionMessageParam],\n        max_tokens: Optional[int] = None\n    ) -> GrokResponse:\n        \"\"\"Get a streaming completion.\"\"\"\n        content_parts = []\n        \n        for attempt in range(self.max_retries):\n            try:\n                stream = await self.client.chat.completions.create(\n                    model=self.model,\n                    messages=messages,\n                    temperature=self.temperature,\n                    max_tokens=max_tokens,\n                    stream=True\n                )\n                \n                async for chunk in stream:\n                    if chunk.choices[0].delta.content:\n                        content_parts.append(chunk.choices[0].delta.content)\n                \n                content = \"\".join(content_parts)\n                # Estimate tokens for streaming (rough approximation)\n                tokens = len(content) // 4\n                self.total_tokens_used += tokens\n                \n                return GrokResponse(\n                    content=content,\n                    tokens_used=tokens,\n                    model=self.model,\n                    timestamp=time.time(),\n                    streaming=True\n                )\n                \n            except openai.RateLimitError as e:\n                wait_time = self.retry_delay * (2 ** attempt)\n                logger.warning(f\"Rate limit hit, waiting {wait_time}s: {e}\")\n                await asyncio.sleep(wait_time)\n                \n            except Exception as e:\n                if attempt == self.max_retries - 1:\n                    logger.error(f\"Failed after {self.max_retries} attempts: {e}\")\n                    raise\n                wait_time = self.retry_delay * (2 ** attempt)\n                logger.warning(f\"Attempt {attempt + 1} failed, retrying in {wait_time}s: {e}\")\n                await asyncio.sleep(wait_time)\n                \n        raise Exception(f\"Failed to get streaming completion after {self.max_retries} attempts\")\n    \n    async def stream_ask(\n        self,\n        prompt: str,\n        system_prompt: Optional[str] = None,\n        max_tokens: Optional[int] = None\n    ) -> AsyncGenerator[str, None]:\n        \"\"\"Stream a response token by token.\n        \n        Args:\n            prompt: User prompt/question\n            system_prompt: Optional system prompt\n            max_tokens: Maximum tokens in response\n            \n        Yields:\n            Response chunks as they arrive\n        \"\"\"\n        messages: List[ChatCompletionMessageParam] = []\n        \n        if system_prompt:\n            messages.append({\"role\": \"system\", \"content\": system_prompt})\n        messages.append({\"role\": \"user\", \"content\": prompt})\n        \n        for attempt in range(self.max_retries):\n            try:\n                stream = await self.client.chat.completions.create(\n                    model=self.model,\n                    messages=messages,\n                    temperature=self.temperature,\n                    max_tokens=max_tokens,\n                    stream=True\n                )\n                \n                async for chunk in stream:\n                    if chunk.choices[0].delta.content:\n                        yield chunk.choices[0].delta.content\n                return\n                \n            except openai.RateLimitError as e:\n                wait_time = self.retry_delay * (2 ** attempt)\n                logger.warning(f\"Rate limit hit, waiting {wait_time}s: {e}\")\n                await asyncio.sleep(wait_time)\n                \n            except Exception as e:\n                if attempt == self.max_retries - 1:\n                    logger.error(f\"Failed after {self.max_retries} attempts: {e}\")\n                    raise\n                wait_time = self.retry_delay * (2 ** attempt)\n                logger.warning(f\"Attempt {attempt + 1} failed, retrying in {wait_time}s: {e}\")\n                await asyncio.sleep(wait_time)\n    \n    def estimate_tokens(self, text: str) -> int:\n        \"\"\"Estimate token count for text (rough approximation).\n        \n        Args:\n            text: Text to estimate tokens for\n            \n        Returns:\n            Estimated token count\n        \"\"\"\n        # Rough estimate: 1 token per 4 characters\n        return len(text) // 4\n    \n    def get_total_tokens_used(self) -> int:\n        \"\"\"Get total tokens used across all requests.\"\"\"\n        return self.total_tokens_used\n    \n    def reset_token_counter(self):\n        \"\"\"Reset the total token counter.\"\"\"\n        self.total_tokens_used = 0\n    \n    async def ask_with_history(\n        self,\n        messages: List[Dict[str, str]],\n        model: Optional[str] = None,\n        temperature: Optional[float] = None,\n        max_tokens: Optional[int] = None,\n        stream: bool = False\n    ) -> GrokResponse:\n        \"\"\"Send a conversation with history to Grok.\n        \n        Args:\n            messages: List of message dicts with 'role' and 'content'\n            model: Optional model override\n            temperature: Optional temperature override\n            max_tokens: Maximum tokens in response\n            stream: Whether to stream the response\n            \n        Returns:\n            GrokResponse object with content and metadata\n        \"\"\"\n        # Convert to proper message format\n        formatted_messages: List[ChatCompletionMessageParam] = []\n        for msg in messages:\n            formatted_messages.append({\n                \"role\": msg[\"role\"],\n                \"content\": msg[\"content\"]\n            })\n        \n        # Use provided parameters or defaults\n        actual_model = model or self.model\n        actual_temp = temperature if temperature is not None else self.temperature\n        \n        # Temporarily update instance values\n        old_model = self.model\n        old_temp = self.temperature\n        self.model = actual_model\n        self.temperature = actual_temp\n        \n        try:\n            if stream:\n                response = await self._stream_completion(formatted_messages, max_tokens)\n            else:\n                response = await self._complete(formatted_messages, max_tokens)\n            return response\n        finally:\n            # Restore original values\n            self.model = old_model\n            self.temperature = old_temp\n\n--- File: lib/tools/__init__.py ---\n\"\"\"\nMCP Tools for Grok integration.\n\"\"\"\n\nfrom .ask import AskTool\nfrom .discuss import DiscussTool\nfrom .session import SessionManager, ListSessionsTool, ContinueSessionTool\nfrom .context import AskWithContextTool\nfrom .health import HealthCheckTool\n\n__all__ = [\n    'AskTool',\n    'DiscussTool', \n    'SessionManager',\n    'ListSessionsTool',\n    'ContinueSessionTool',\n    'AskWithContextTool',\n    'HealthCheckTool'\n]\n\n--- File: lib/tools/context_loader.py ---\n\"\"\"\nEnhanced context loader with support for directories, patterns, and file filtering.\n\"\"\"\n\nimport os\nimport glob\nfrom pathlib import Path\nfrom typing import List, Dict, Any, Optional, Union, Tuple\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\nclass ContextLoader:\n    \"\"\"Handles loading context from files, directories, and patterns.\"\"\"\n    \n    # Default file extensions to include when processing directories\n    DEFAULT_EXTENSIONS = {\n        'code': ['.py', '.js', '.ts', '.jsx', '.tsx', '.java', '.cpp', '.c', '.h', '.hpp', \n                 '.cs', '.go', '.rs', '.rb', '.php', '.swift', '.kt', '.scala', '.r', '.m'],\n        'docs': ['.md', '.txt', '.rst', '.adoc', '.tex', '.org'],\n        'config': ['.json', '.yaml', '.yml', '.toml', '.ini', '.cfg', '.conf', '.xml'],\n        'web': ['.html', '.htm', '.css', '.scss', '.sass', '.less'],\n        'data': ['.csv', '.tsv', '.sql'],\n        'all': []  # Empty means all files\n    }\n    \n    # Files/directories to always exclude\n    EXCLUDE_PATTERNS = {\n        '__pycache__', '.git', '.svn', '.hg', 'node_modules', '.venv', 'venv',\n        'env', '.env', '*.pyc', '*.pyo', '*.pyd', '.DS_Store', 'Thumbs.db',\n        '*.egg-info', 'dist', 'build', '.pytest_cache', '.mypy_cache',\n        '.coverage', 'htmlcov', '.tox', '.idea', '.vscode', '*.swp', '*.swo'\n    }\n    \n    @classmethod\n    def load_context(\n        cls,\n        file_specs: List[Union[str, Dict[str, Any]]],\n        max_lines_per_file: int = 100,\n        max_total_lines: int = 10000,\n        context_type: str = 'general'\n    ) -> Tuple[str, Dict[str, Any]]:\n        \"\"\"\n        Load context from various file specifications.\n        \n        Args:\n            file_specs: List of file specifications, can be:\n                - String path to a file or directory\n                - Dict with keys:\n                    - path: str (required) - file, directory, or glob pattern\n                    - from: int (optional) - start line for files\n                    - to: int (optional) - end line for files\n                    - recursive: bool (optional) - for directories\n                    - extensions: List[str] (optional) - file extensions to include\n                    - exclude: List[str] (optional) - patterns to exclude\n                    - pattern: str (optional) - glob pattern for matching files\n            max_lines_per_file: Maximum lines to include per file\n            max_total_lines: Maximum total lines across all files\n            context_type: Type of context ('code', 'docs', 'general', etc.)\n            \n        Returns:\n            Tuple of (context_string, metadata_dict)\n        \"\"\"\n        context_parts = []\n        metadata = {\n            'files_processed': 0,\n            'total_lines': 0,\n            'skipped_files': [],\n            'errors': []\n        }\n        total_lines = 0\n        \n        for spec in file_specs:\n            if total_lines >= max_total_lines:\n                metadata['skipped_files'].append(f\"Remaining files (max lines reached)\")\n                break\n                \n            try:\n                files_to_process = cls._resolve_file_spec(spec, context_type)\n                \n                for file_info in files_to_process:\n                    if total_lines >= max_total_lines:\n                        metadata['skipped_files'].append(file_info['path'])\n                        continue\n                        \n                    file_path = file_info['path']\n                    from_line = file_info.get('from')\n                    to_line = file_info.get('to')\n                    \n                    # Load the file content\n                    content, lines_read = cls._load_file_content(\n                        file_path, \n                        from_line, \n                        to_line,\n                        max_lines_per_file,\n                        max_total_lines - total_lines\n                    )\n                    \n                    if content:\n                        # Add file header\n                        header = f\"\\n--- File: {file_path}\"\n                        if from_line or to_line:\n                            header += f\" (lines {from_line or 1}-{to_line or lines_read})\"\n                        header += \" ---\\n\"\n                        \n                        context_parts.append(header + content)\n                        metadata['files_processed'] += 1\n                        total_lines += lines_read\n                        metadata['total_lines'] = total_lines\n                    \n            except Exception as e:\n                logger.error(f\"Error processing spec {spec}: {e}\")\n                metadata['errors'].append(f\"Error with {spec}: {str(e)}\")\n        \n        context = \"\\n\".join(context_parts)\n        return context, metadata\n    \n    @classmethod\n    def _resolve_file_spec(\n        cls,\n        spec: Union[str, Dict[str, Any]],\n        context_type: str\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Resolve a file specification to a list of file paths with metadata.\n        \n        Returns:\n            List of dicts with 'path' and optional 'from'/'to' keys\n        \"\"\"\n        if isinstance(spec, str):\n            # Simple string path\n            path = Path(spec)\n            \n            if '*' in spec or '?' in spec or '[' in spec:\n                # It's a glob pattern\n                return cls._resolve_glob_pattern(spec)\n            elif path.is_file():\n                # Single file\n                return [{'path': str(path)}]\n            elif path.is_dir():\n                # Directory - use default extensions for context type\n                extensions = cls.DEFAULT_EXTENSIONS.get(context_type, cls.DEFAULT_EXTENSIONS['all'])\n                # For string directories, use recursive=True by default\n                return cls._resolve_directory(str(path), recursive=True, extensions=extensions)\n            else:\n                logger.warning(f\"Path not found: {spec}\")\n                return []\n                \n        elif isinstance(spec, dict):\n            path = spec.get('path', '')\n            \n            if not path:\n                logger.warning(\"No path specified in file spec\")\n                return []\n            \n            # Check for explicit pattern field\n            pattern = spec.get('pattern')\n            if pattern:\n                # Pattern is relative to the path\n                base_path = path if Path(path).is_dir() else '.'\n                full_pattern = os.path.join(base_path, pattern)\n                return cls._resolve_glob_pattern(full_pattern)\n            \n            # Check for glob pattern in the path itself\n            if '*' in path or '?' in path or '[' in path:\n                return cls._resolve_glob_pattern(path)\n            \n            path_obj = Path(path)\n            \n            if path_obj.is_file():\n                # Single file with optional line ranges\n                return [{\n                    'path': str(path_obj),\n                    'from': spec.get('from'),\n                    'to': spec.get('to')\n                }]\n            elif path_obj.is_dir():\n                # Directory with options\n                recursive = spec.get('recursive', True)\n                extensions = spec.get('extensions', \n                                     cls.DEFAULT_EXTENSIONS.get(context_type, cls.DEFAULT_EXTENSIONS['all']))\n                exclude = spec.get('exclude', [])\n                \n                return cls._resolve_directory(\n                    str(path_obj),\n                    recursive=recursive,\n                    extensions=extensions,\n                    exclude=exclude\n                )\n            else:\n                logger.warning(f\"Path not found: {path}\")\n                return []\n        \n        return []\n    \n    @classmethod\n    def _resolve_directory(\n        cls,\n        directory: str,\n        recursive: bool = True,\n        extensions: Optional[List[str]] = None,\n        exclude: Optional[List[str]] = None\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Resolve a directory to a list of file paths.\n        \"\"\"\n        files = []\n        exclude_patterns = set(cls.EXCLUDE_PATTERNS)\n        if exclude:\n            exclude_patterns.update(exclude)\n        \n        for root, dirs, filenames in os.walk(directory):\n            # Filter out excluded directories\n            dirs[:] = [d for d in dirs if not cls._should_exclude(d, exclude_patterns)]\n            \n            for filename in filenames:\n                # Check if file should be excluded\n                if cls._should_exclude(filename, exclude_patterns):\n                    continue\n                \n                # Check extension if specified\n                if extensions and not any(filename.endswith(ext) for ext in extensions):\n                    continue\n                \n                file_path = os.path.join(root, filename)\n                files.append({'path': file_path})\n            \n            if not recursive:\n                break\n        \n        return files\n    \n    @classmethod\n    def _resolve_glob_pattern(cls, pattern: str) -> List[Dict[str, Any]]:\n        \"\"\"\n        Resolve a glob pattern to a list of file paths.\n        \"\"\"\n        files = []\n        for path in glob.glob(pattern, recursive=True):\n            if os.path.isfile(path):\n                # Check if it should be excluded\n                if not cls._should_exclude(path, cls.EXCLUDE_PATTERNS):\n                    files.append({'path': path})\n        return files\n    \n    @classmethod\n    def _should_exclude(cls, path: str, exclude_patterns: set) -> bool:\n        \"\"\"\n        Check if a path should be excluded based on patterns.\n        \"\"\"\n        path_parts = Path(path).parts\n        \n        for pattern in exclude_patterns:\n            # Check exact match\n            if any(part == pattern for part in path_parts):\n                return True\n            \n            # Check wildcard patterns\n            if '*' in pattern:\n                import fnmatch\n                if fnmatch.fnmatch(os.path.basename(path), pattern):\n                    return True\n        \n        return False\n    \n    @classmethod\n    def _load_file_content(\n        cls,\n        file_path: str,\n        from_line: Optional[int] = None,\n        to_line: Optional[int] = None,\n        max_lines: int = 100,\n        remaining_total: int = None\n    ) -> Tuple[str, int]:\n        \"\"\"\n        Load content from a file with optional line range.\n        \n        Returns:\n            Tuple of (content_string, lines_read)\n        \"\"\"\n        try:\n            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n                lines = f.readlines()\n            \n            # Apply line range if specified\n            if from_line is not None:\n                from_idx = max(0, from_line - 1)  # Convert to 0-based index\n            else:\n                from_idx = 0\n            \n            if to_line is not None:\n                to_idx = min(len(lines), to_line)  # to_line is inclusive\n            else:\n                to_idx = len(lines)\n            \n            lines = lines[from_idx:to_idx]\n            \n            # Apply max lines limit\n            if len(lines) > max_lines:\n                truncated_lines = lines[:max_lines]\n                truncated_lines.append(\"... (truncated, showing first {} lines)\\n\".format(max_lines))\n                lines = truncated_lines\n            \n            # Apply remaining total limit if specified\n            if remaining_total is not None and len(lines) > remaining_total:\n                lines = lines[:remaining_total]\n                lines.append(\"... (truncated due to total line limit)\\n\")\n            \n            # Count actual content lines (not truncation messages)\n            actual_lines = [l for l in lines if not l.startswith('...')]\n            content = ''.join(lines)\n            lines_read = len(actual_lines)\n            \n            return content, lines_read\n            \n        except Exception as e:\n            logger.error(f\"Error reading file {file_path}: {e}\")\n            return f\"Error reading file: {str(e)}\\n\", 0\n\n--- File: lib/tools/ask.py ---\n\"\"\"\nBasic ask tool - backward compatible with simple_mcp.py.\n\"\"\"\n\nfrom typing import Any, Dict\nfrom .base import BaseTool\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\nclass AskTool(BaseTool):\n    \"\"\"Simple question-answer tool.\"\"\"\n    \n    @property\n    def name(self) -> str:\n        return \"grok_ask\"\n    \n    @property\n    def description(self) -> str:\n        return \"Ask Grok a question\"\n    \n    @property\n    def input_schema(self) -> Dict[str, Any]:\n        return {\n            \"type\": \"object\",\n            \"properties\": {\n                \"question\": {\n                    \"type\": \"string\",\n                    \"description\": \"The question to ask\"\n                },\n                \"model\": {\n                    \"type\": \"string\",\n                    \"description\": \"Model to use\",\n                    \"enum\": [\"grok-4-fast-reasoning\", \"grok-4-0709\", \"grok-2-1212\", \"grok-2-vision\", \"grok-beta\"],\n                    \"default\": \"grok-4-fast-reasoning\"\n                },\n                \"temperature\": {\n                    \"type\": \"number\",\n                    \"description\": \"Temperature for response\",\n                    \"minimum\": 0.0,\n                    \"maximum\": 2.0,\n                    \"default\": 0.7\n                },\n                \"stream\": {\n                    \"type\": \"boolean\",\n                    \"description\": \"Stream the response\",\n                    \"default\": False\n                }\n            },\n            \"required\": [\"question\"]\n        }\n    \n    async def execute(self, question: str, model: str = None, \n                     temperature: float = None, stream: bool = False, **kwargs) -> str:\n        \"\"\"Execute the ask tool.\"\"\"\n        try:\n            # Use provided parameters or defaults\n            actual_model = model or \"grok-4-fast-reasoning\"\n            actual_temp = temperature if temperature is not None else 0.7\n            \n            # For now, ignore streaming (Phase 2)\n            response = await self.grok_client.ask(\n                prompt=question,\n                stream=False  # Will implement streaming in Phase 2\n            )\n            \n            return response.content\n            \n        except Exception as e:\n            logger.error(f\"Error in grok_ask: {e}\")\n            # Return error message instead of raising\n            return f\"Error: {str(e)}\"\n\n--- File: lib/tools/discuss.py ---\n\"\"\"\nDiscussion tool for multi-turn conversations with file context support and pagination.\n\"\"\"\n\nimport os\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Optional\nfrom .base import BaseTool\nfrom .session import SessionManager\nfrom .context_loader import ContextLoader\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\nclass DiscussTool(BaseTool):\n    \"\"\"Tool for extended discussions with Grok, supporting file context and pagination.\"\"\"\n    \n    def __init__(self, grok_client, session_manager: SessionManager):\n        super().__init__(grok_client)\n        self.session_manager = session_manager\n    \n    @property\n    def name(self) -> str:\n        return \"grok_discuss\"\n    \n    @property\n    def description(self) -> str:\n        return \"Start an extended discussion with Grok\"\n    \n    @property\n    def input_schema(self) -> Dict[str, Any]:\n        return {\n            \"type\": \"object\",\n            \"properties\": {\n                \"topic\": {\n                    \"type\": \"string\",\n                    \"description\": \"Discussion topic\"\n                },\n                \"context\": {\n                    \"type\": \"string\",\n                    \"description\": \"Optional context for the discussion\"\n                },\n                \"context_files\": {\n                    \"type\": \"array\",\n                    \"items\": {\n                        \"oneOf\": [\n                            {\"type\": \"string\", \"description\": \"File path, directory path, or glob pattern\"},\n                            {\n                                \"type\": \"object\",\n                                \"properties\": {\n                                    \"path\": {\"type\": \"string\", \"description\": \"File path, directory path, or glob pattern\"},\n                                    \"from\": {\"type\": \"integer\", \"description\": \"Start line number (1-based) for files\", \"minimum\": 1},\n                                    \"to\": {\"type\": \"integer\", \"description\": \"End line number (1-based) for files\", \"minimum\": 1},\n                                    \"recursive\": {\"type\": \"boolean\", \"description\": \"Recursive directory traversal\", \"default\": True},\n                                    \"extensions\": {\n                                        \"type\": \"array\", \n                                        \"items\": {\"type\": \"string\"},\n                                        \"description\": \"File extensions to include (e.g., ['.py', '.js'])\"\n                                    },\n                                    \"exclude\": {\n                                        \"type\": \"array\",\n                                        \"items\": {\"type\": \"string\"},\n                                        \"description\": \"Patterns to exclude (e.g., ['test_*', '*.pyc'])\"\n                                    },\n                                    \"pattern\": {\"type\": \"string\", \"description\": \"Glob pattern for file matching\"}\n                                },\n                                \"required\": [\"path\"]\n                            }\n                        ]\n                    },\n                    \"description\": \"List of files, directories, or patterns. Supports: file paths, directories (with recursive/extension options), glob patterns ('**/*.py'), and line ranges\"\n                },\n                \"context_type\": {\n                    \"type\": \"string\",\n                    \"description\": \"Type of context\",\n                    \"enum\": [\"code\", \"docs\", \"general\"],\n                    \"default\": \"general\"\n                },\n                \"max_context_lines\": {\n                    \"type\": \"integer\",\n                    \"description\": \"Maximum lines per file\",\n                    \"default\": 100\n                },\n                \"max_total_context_lines\": {\n                    \"type\": \"integer\",\n                    \"description\": \"Maximum total lines across all files\",\n                    \"default\": 2000000\n                },\n                \"max_turns\": {\n                    \"type\": \"integer\",\n                    \"description\": \"Maximum conversation turns\",\n                    \"minimum\": 1,\n                    \"maximum\": 10,\n                    \"default\": 3\n                },\n                \"expert_mode\": {\n                    \"type\": \"boolean\",\n                    \"description\": \"Include expert perspectives\",\n                    \"default\": False\n                },\n                \"page\": {\n                    \"type\": \"integer\",\n                    \"description\": \"Page number for paginated results (1-based)\",\n                    \"minimum\": 1,\n                    \"default\": 1\n                },\n                \"turns_per_page\": {\n                    \"type\": \"integer\",\n                    \"description\": \"Number of turns to include per page\",\n                    \"minimum\": 1,\n                    \"maximum\": 5,\n                    \"default\": 2\n                },\n                \"paginate\": {\n                    \"type\": \"boolean\",\n                    \"description\": \"Enable pagination (default: true)\",\n                    \"default\": True\n                },\n                \"session_id\": {\n                    \"type\": \"string\",\n                    \"description\": \"Session ID to continue an existing discussion\"\n                }\n            },\n            \"required\": [\"topic\"]\n        }\n    \n    async def execute(self, topic: str, context: str = None, \n                     context_files: List[str] = None,\n                     context_type: str = \"general\",\n                     max_context_lines: int = 100,\n                     max_total_context_lines: int = 2000000,\n                     max_turns: int = 3, expert_mode: bool = False,\n                     page: int = 1, turns_per_page: int = 2, \n                     paginate: bool = True, **kwargs) -> str:\n        \"\"\"Start a discussion with optional file context and pagination support.\"\"\"\n        try:\n            # Create a new session or continue existing one\n            session_id = kwargs.get('session_id')\n            if not session_id:\n                session_id = self.session_manager.create_session(topic)\n                \n                # Build file context if provided\n                file_context = \"\"\n                file_metadata = {}\n                if context_files:\n                    file_context, file_metadata = ContextLoader.load_context(\n                        context_files,\n                        max_lines_per_file=max_context_lines,\n                        max_total_lines=max_total_context_lines,\n                        context_type=context_type\n                    )\n                \n                # Build initial prompt\n                initial_prompt = f\"Let's discuss: {topic}\"\n                \n                # Add file context first if provided\n                if file_context:\n                    initial_prompt = self._build_contextual_prompt(initial_prompt, file_context, context_type)\n                \n                # Add additional context if provided\n                if context:\n                    initial_prompt += f\"\\n\\nAdditional context: {context}\"\n                \n                if expert_mode:\n                    initial_prompt += \"\\n\\nPlease provide expert-level insights with multiple perspectives.\"\n                \n                # Add initial user message\n                self.session_manager.add_message(session_id, \"user\", initial_prompt)\n                messages = [{\"role\": \"user\", \"content\": initial_prompt}]\n            else:\n                # Load existing session messages\n                session = self.session_manager.get_session(session_id)\n                if not session:\n                    return f\"Error: Session {session_id} not found\"\n                messages = session['messages']\n                # Extract context_files from kwargs if continuing a session\n                context_files = kwargs.get('context_files')\n            \n            # Calculate pagination\n            if paginate:\n                start_turn = (page - 1) * turns_per_page\n                end_turn = min(start_turn + turns_per_page, max_turns)\n                total_pages = (max_turns + turns_per_page - 1) // turns_per_page\n                \n                if start_turn >= max_turns:\n                    return f\"Error: Page {page} exceeds total pages ({total_pages})\"\n            else:\n                start_turn = 0\n                end_turn = max_turns\n                total_pages = 1\n            \n            # Start the discussion\n            result = f\"Discussion on: {topic}\\n\"\n            result += f\"Session ID: {session_id}\\n\"\n            \n            if context_files:\n                # Format context files for display\n                file_list = []\n                for file_spec in context_files:\n                    if isinstance(file_spec, str):\n                        file_list.append(file_spec)\n                    elif isinstance(file_spec, dict):\n                        path = file_spec['path']\n                        if 'from' in file_spec or 'to' in file_spec:\n                            from_line = file_spec.get('from', '?')\n                            to_line = file_spec.get('to', '?')\n                            file_list.append(f\"{path}:{from_line}-{to_line}\")\n                        elif 'pattern' in file_spec:\n                            file_list.append(f\"Pattern: {file_spec['pattern']}\")\n                        elif 'recursive' in file_spec or 'extensions' in file_spec:\n                            desc = path\n                            if file_spec.get('recursive'):\n                                desc += \" (recursive)\"\n                            if 'extensions' in file_spec:\n                                desc += f\" [{', '.join(file_spec['extensions'])}]\"\n                            file_list.append(desc)\n                        else:\n                            file_list.append(path)\n                result += f\"Context: {', '.join(file_list)}\\n\"\n                if file_metadata and 'files_processed' in file_metadata:\n                    result += f\"Files loaded: {file_metadata['files_processed']}, Total lines: {file_metadata.get('total_lines', 0)}\\n\"\n            \n            if paginate:\n                result += f\"Page {page} of {total_pages} (Turns {start_turn + 1}-{end_turn} of {max_turns})\\n\"\n            else:\n                result += f\"Max turns: {max_turns}\\n\"\n            \n            result += \"=\" * 50 + \"\\n\\n\"\n            \n            # Get the current turn count from session\n            current_turn_count = len([m for m in messages if m['role'] == 'assistant'])\n            \n            # Execute turns for this page\n            for turn in range(start_turn, end_turn):\n                # Skip if turn already exists\n                if turn < current_turn_count:\n                    # Get existing turn from messages\n                    assistant_messages = [m for m in messages if m['role'] == 'assistant']\n                    if turn < len(assistant_messages):\n                        result += f\"Turn {turn + 1}:\\n{assistant_messages[turn]['content']}\\n\\n\"\n                        \n                        # Add follow-up if exists\n                        user_messages = [m for m in messages if m['role'] == 'user']\n                        if turn + 1 < len(user_messages) - 1:  # -1 for initial prompt\n                            result += f\"Follow-up: {user_messages[turn + 2]['content']}\\n\\n\"\n                    continue\n                \n                # Generate new turn\n                response = await self.grok_client.ask_with_history(\n                    messages=messages,\n                    stream=False\n                )\n                \n                # Add to session\n                self.session_manager.add_message(session_id, \"assistant\", response.content)\n                messages.append({\"role\": \"assistant\", \"content\": response.content})\n                \n                result += f\"Turn {turn + 1}:\\n{response.content}\\n\\n\"\n                \n                # Generate follow-up question if not last turn on this page\n                if turn < end_turn - 1:\n                    follow_up = self._generate_follow_up(response.content, expert_mode, context_files is not None)\n                    self.session_manager.add_message(session_id, \"user\", follow_up)\n                    messages.append({\"role\": \"user\", \"content\": follow_up})\n                    result += f\"Follow-up: {follow_up}\\n\\n\"\n            \n            # Add pagination info and navigation\n            if paginate:\n                result += \"\\n\" + \"=\" * 50 + \"\\n\"\n                result += f\"Page {page} of {total_pages}\\n\"\n                \n                if page < total_pages:\n                    result += f\"\\nTo continue, use: grok_discuss with session_id='{session_id}' and page={page + 1}\"\n                else:\n                    # Close the session only when reaching the last page\n                    self.session_manager.close_session(session_id)\n                    result += f\"\\nDiscussion completed. Session ID: {session_id}\"\n            else:\n                # Close the session for non-paginated discussions\n                self.session_manager.close_session(session_id)\n                result += f\"\\nDiscussion completed. Session ID: {session_id}\"\n            \n            return result\n            \n        except Exception as e:\n            logger.error(f\"Error in discussion: {e}\")\n            return f\"Error: {str(e)}\"\n    \n    \n    def _build_contextual_prompt(self, base_prompt: str, file_context: str, context_type: str) -> str:\n        \"\"\"Build a prompt with file context.\"\"\"\n        if not file_context:\n            return base_prompt\n        \n        if context_type == \"code\":\n            prompt = f\"Given the following code:\\n{file_context}\\n\\n{base_prompt}\"\n        elif context_type == \"docs\":\n            prompt = f\"Based on this documentation:\\n{file_context}\\n\\n{base_prompt}\"\n        else:\n            prompt = f\"Context:\\n{file_context}\\n\\n{base_prompt}\"\n        \n        return prompt\n    \n    def _generate_follow_up(self, response: str, expert_mode: bool, has_file_context: bool = False) -> str:\n        \"\"\"Generate a follow-up question based on the response.\"\"\"\n        if has_file_context:\n            if expert_mode:\n                return \"How does this relate to the code structure and what optimizations or refactoring would you suggest?\"\n            else:\n                return \"Can you explain how this applies to the specific code we're discussing?\"\n        else:\n            if expert_mode:\n                return \"Can you elaborate on the technical implications and potential edge cases?\"\n            else:\n                return \"Can you provide more details or examples?\"\n\n--- File: lib/tools/base.py ---\n\"\"\"\nBase class for MCP tools.\n\"\"\"\n\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Dict, Optional\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\nclass BaseTool(ABC):\n    \"\"\"Base class for all MCP tools.\"\"\"\n    \n    def __init__(self, grok_client):\n        \"\"\"Initialize the tool with a Grok client.\"\"\"\n        self.grok_client = grok_client\n    \n    @property\n    @abstractmethod\n    def name(self) -> str:\n        \"\"\"Return the tool name.\"\"\"\n        pass\n    \n    @property\n    @abstractmethod\n    def description(self) -> str:\n        \"\"\"Return the tool description.\"\"\"\n        pass\n    \n    @property\n    @abstractmethod\n    def input_schema(self) -> Dict[str, Any]:\n        \"\"\"Return the JSON schema for tool inputs.\"\"\"\n        pass\n    \n    @abstractmethod\n    async def execute(self, **kwargs) -> str:\n        \"\"\"Execute the tool with given arguments.\"\"\"\n        pass\n    \n    def to_mcp_tool(self) -> Dict[str, Any]:\n        \"\"\"Convert to MCP tool definition.\"\"\"\n        return {\n            \"name\": self.name,\n            \"description\": self.description,\n            \"inputSchema\": self.input_schema\n        }\n\n--- File: lib/tools/context.py ---\n\"\"\"\nContext-aware question tool.\n\"\"\"\n\nfrom pathlib import Path\nfrom typing import Any, Dict, List\nfrom .base import BaseTool\nfrom .context_loader import ContextLoader\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\nclass AskWithContextTool(BaseTool):\n    \"\"\"Tool for asking questions with file/code context.\"\"\"\n    \n    @property\n    def name(self) -> str:\n        return \"grok_ask_with_context\"\n    \n    @property\n    def description(self) -> str:\n        return \"Ask Grok a question with file/code context\"\n    \n    @property\n    def input_schema(self) -> Dict[str, Any]:\n        return {\n            \"type\": \"object\",\n            \"properties\": {\n                \"question\": {\n                    \"type\": \"string\",\n                    \"description\": \"The question to ask\"\n                },\n                \"context_files\": {\n                    \"type\": \"array\",\n                    \"items\": {\n                        \"oneOf\": [\n                            {\"type\": \"string\", \"description\": \"File path, directory path, or glob pattern\"},\n                            {\n                                \"type\": \"object\",\n                                \"properties\": {\n                                    \"path\": {\"type\": \"string\", \"description\": \"File path, directory path, or glob pattern\"},\n                                    \"from\": {\"type\": \"integer\", \"description\": \"Start line number (1-based) for files\", \"minimum\": 1},\n                                    \"to\": {\"type\": \"integer\", \"description\": \"End line number (1-based) for files\", \"minimum\": 1},\n                                    \"recursive\": {\"type\": \"boolean\", \"description\": \"Recursive directory traversal\", \"default\": True},\n                                    \"extensions\": {\n                                        \"type\": \"array\", \n                                        \"items\": {\"type\": \"string\"},\n                                        \"description\": \"File extensions to include (e.g., ['.py', '.js'])\"\n                                    },\n                                    \"exclude\": {\n                                        \"type\": \"array\",\n                                        \"items\": {\"type\": \"string\"},\n                                        \"description\": \"Patterns to exclude (e.g., ['test_*', '*.pyc'])\"\n                                    },\n                                    \"pattern\": {\"type\": \"string\", \"description\": \"Glob pattern for file matching\"}\n                                },\n                                \"required\": [\"path\"]\n                            }\n                        ]\n                    },\n                    \"description\": \"List of files, directories, or patterns. Supports: file paths, directories (with recursive/extension options), glob patterns ('**/*.py'), and line ranges\"\n                },\n                \"context_type\": {\n                    \"type\": \"string\",\n                    \"description\": \"Type of context\",\n                    \"enum\": [\"code\", \"docs\", \"general\"],\n                    \"default\": \"general\"\n                },\n                \"max_context_lines\": {\n                    \"type\": \"integer\",\n                    \"description\": \"Maximum lines per file\",\n                    \"default\": 100\n                },\n                \"max_total_context_lines\": {\n                    \"type\": \"integer\",\n                    \"description\": \"Maximum total lines across all files\",\n                    \"default\": 2000000\n                }\n            },\n            \"required\": [\"question\"]\n        }\n    \n    async def execute(self, question: str, context_files: List[str] = None,\n                     context_type: str = \"general\", max_context_lines: int = 100,\n                     max_total_context_lines: int = 2000000, **kwargs) -> str:\n        \"\"\"Execute with context.\"\"\"\n        try:\n            # Build context from files\n            context = \"\"\n            metadata = {}\n            if context_files:\n                context, metadata = ContextLoader.load_context(\n                    context_files,\n                    max_lines_per_file=max_context_lines,\n                    max_total_lines=max_total_context_lines,\n                    context_type=context_type\n                )\n            \n            # Build the prompt\n            prompt = self._build_contextual_prompt(question, context, context_type)\n            \n            # Get response\n            response = await self.grok_client.ask(prompt=prompt, stream=False)\n            \n            # Add metadata info if relevant\n            result = response.content\n            if metadata and metadata.get('files_processed', 0) > 0:\n                result += f\"\\n\\n[Context: {metadata['files_processed']} files, {metadata.get('total_lines', 0)} lines]\"\n                if metadata.get('errors'):\n                    result += f\"\\n[Errors: {'; '.join(metadata['errors'])}]\"\n            \n            return result\n            \n        except Exception as e:\n            logger.error(f\"Error in context-aware ask: {e}\")\n            return f\"Error: {str(e)}\"\n    \n    \n    def _build_contextual_prompt(self, question: str, context: str, context_type: str) -> str:\n        \"\"\"Build a prompt with context.\"\"\"\n        if not context:\n            return question\n        \n        if context_type == \"code\":\n            prompt = f\"Given the following code:\\n{context}\\n\\n{question}\"\n        elif context_type == \"docs\":\n            prompt = f\"Based on this documentation:\\n{context}\\n\\n{question}\"\n        else:\n            prompt = f\"Context:\\n{context}\\n\\nQuestion: {question}\"\n        \n        return prompt\n\n--- File: lib/tools/session.py ---\n\"\"\"\nSession management tools for multi-turn conversations.\n\"\"\"\n\nimport json\nimport uuid\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Optional\nfrom .base import BaseTool\nfrom .context_loader import ContextLoader\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\nclass SessionManager:\n    \"\"\"Manages conversation sessions.\"\"\"\n    \n    def __init__(self, storage_path: Path = None):\n        \"\"\"Initialize session manager.\"\"\"\n        self.storage_path = storage_path or Path(\"./sessions\")\n        self.storage_path.mkdir(exist_ok=True)\n        self.sessions = {}\n        self._load_sessions()\n    \n    def _load_sessions(self):\n        \"\"\"Load existing sessions from disk.\"\"\"\n        for session_file in self.storage_path.glob(\"*.json\"):\n            try:\n                with open(session_file, 'r') as f:\n                    session = json.load(f)\n                    self.sessions[session['id']] = session\n            except Exception as e:\n                logger.error(f\"Failed to load session {session_file}: {e}\")\n    \n    def create_session(self, topic: str) -> str:\n        \"\"\"Create a new session.\"\"\"\n        session_id = str(uuid.uuid4())\n        session = {\n            \"id\": session_id,\n            \"topic\": topic,\n            \"created_at\": datetime.now().isoformat(),\n            \"updated_at\": datetime.now().isoformat(),\n            \"messages\": [],\n            \"status\": \"active\"\n        }\n        self.sessions[session_id] = session\n        self._save_session(session_id)\n        return session_id\n    \n    def add_message(self, session_id: str, role: str, content: str):\n        \"\"\"Add a message to a session.\"\"\"\n        if session_id not in self.sessions:\n            raise ValueError(f\"Session {session_id} not found\")\n        \n        self.sessions[session_id][\"messages\"].append({\n            \"role\": role,\n            \"content\": content,\n            \"timestamp\": datetime.now().isoformat()\n        })\n        self.sessions[session_id][\"updated_at\"] = datetime.now().isoformat()\n        self._save_session(session_id)\n    \n    def get_session(self, session_id: str) -> Optional[Dict]:\n        \"\"\"Get a session by ID.\"\"\"\n        return self.sessions.get(session_id)\n    \n    def list_sessions(self, status: str = None, limit: int = 10) -> List[Dict]:\n        \"\"\"List sessions with optional filtering.\"\"\"\n        sessions = list(self.sessions.values())\n        \n        if status:\n            sessions = [s for s in sessions if s.get(\"status\") == status]\n        \n        # Sort by updated_at descending\n        sessions.sort(key=lambda x: x.get(\"updated_at\", \"\"), reverse=True)\n        \n        return sessions[:limit]\n    \n    def _save_session(self, session_id: str):\n        \"\"\"Save a session to disk.\"\"\"\n        session = self.sessions[session_id]\n        session_file = self.storage_path / f\"{session_id}.json\"\n        with open(session_file, 'w') as f:\n            json.dump(session, f, indent=2)\n    \n    def close_session(self, session_id: str):\n        \"\"\"Mark a session as completed.\"\"\"\n        if session_id in self.sessions:\n            self.sessions[session_id][\"status\"] = \"completed\"\n            self.sessions[session_id][\"updated_at\"] = datetime.now().isoformat()\n            self._save_session(session_id)\n\n\nclass ListSessionsTool(BaseTool):\n    \"\"\"Tool to list conversation sessions.\"\"\"\n    \n    def __init__(self, grok_client, session_manager: SessionManager):\n        super().__init__(grok_client)\n        self.session_manager = session_manager\n    \n    @property\n    def name(self) -> str:\n        return \"grok_list_sessions\"\n    \n    @property\n    def description(self) -> str:\n        return \"List conversation sessions\"\n    \n    @property\n    def input_schema(self) -> Dict[str, Any]:\n        return {\n            \"type\": \"object\",\n            \"properties\": {\n                \"status\": {\n                    \"type\": \"string\",\n                    \"description\": \"Filter by status\",\n                    \"enum\": [\"active\", \"completed\", \"failed\", \"paused\"]\n                },\n                \"limit\": {\n                    \"type\": \"integer\",\n                    \"description\": \"Maximum sessions to return\",\n                    \"minimum\": 1,\n                    \"maximum\": 100,\n                    \"default\": 10\n                }\n            }\n        }\n    \n    async def execute(self, status: str = None, limit: int = 10, **kwargs) -> str:\n        \"\"\"List sessions.\"\"\"\n        try:\n            sessions = self.session_manager.list_sessions(status, limit)\n            \n            if not sessions:\n                return \"No sessions found.\"\n            \n            result = f\"Found {len(sessions)} session(s):\\n\\n\"\n            for session in sessions:\n                result += f\"ID: {session['id']}\\n\"\n                result += f\"Topic: {session['topic']}\\n\"\n                result += f\"Status: {session['status']}\\n\"\n                result += f\"Messages: {len(session['messages'])}\\n\"\n                result += f\"Updated: {session['updated_at']}\\n\"\n                result += \"-\" * 40 + \"\\n\"\n            \n            return result\n            \n        except Exception as e:\n            logger.error(f\"Error listing sessions: {e}\")\n            return f\"Error: {str(e)}\"\n\n\nclass ContinueSessionTool(BaseTool):\n    \"\"\"Tool to continue a conversation session.\"\"\"\n    \n    def __init__(self, grok_client, session_manager: SessionManager):\n        super().__init__(grok_client)\n        self.session_manager = session_manager\n    \n    @property\n    def name(self) -> str:\n        return \"grok_continue_session\"\n    \n    @property\n    def description(self) -> str:\n        return \"Continue a previous conversation\"\n    \n    @property\n    def input_schema(self) -> Dict[str, Any]:\n        return {\n            \"type\": \"object\",\n            \"properties\": {\n                \"session_id\": {\n                    \"type\": \"string\",\n                    \"description\": \"Session ID to continue\"\n                },\n                \"message\": {\n                    \"type\": \"string\",\n                    \"description\": \"Your message to continue the conversation\"\n                },\n                \"context_files\": {\n                    \"type\": \"array\",\n                    \"items\": {\n                        \"oneOf\": [\n                            {\"type\": \"string\", \"description\": \"File path, directory path, or glob pattern\"},\n                            {\n                                \"type\": \"object\",\n                                \"properties\": {\n                                    \"path\": {\"type\": \"string\", \"description\": \"File path, directory path, or glob pattern\"},\n                                    \"from\": {\"type\": \"integer\", \"description\": \"Start line number (1-based) for files\", \"minimum\": 1},\n                                    \"to\": {\"type\": \"integer\", \"description\": \"End line number (1-based) for files\", \"minimum\": 1},\n                                    \"recursive\": {\"type\": \"boolean\", \"description\": \"Recursive directory traversal\", \"default\": True},\n                                    \"extensions\": {\n                                        \"type\": \"array\", \n                                        \"items\": {\"type\": \"string\"},\n                                        \"description\": \"File extensions to include (e.g., ['.py', '.js'])\"\n                                    },\n                                    \"exclude\": {\n                                        \"type\": \"array\",\n                                        \"items\": {\"type\": \"string\"},\n                                        \"description\": \"Patterns to exclude (e.g., ['test_*', '*.pyc'])\"\n                                    },\n                                    \"pattern\": {\"type\": \"string\", \"description\": \"Glob pattern for file matching\"}\n                                },\n                                \"required\": [\"path\"]\n                            }\n                        ]\n                    },\n                    \"description\": \"Optional files, directories, or patterns. Supports: file paths, directories (with recursive/extension options), glob patterns ('**/*.py'), and line ranges\"\n                },\n                \"max_context_lines\": {\n                    \"type\": \"integer\",\n                    \"description\": \"Maximum lines per file to include\",\n                    \"default\": 500\n                },\n                \"max_total_context_lines\": {\n                    \"type\": \"integer\",\n                    \"description\": \"Maximum total lines across all files\",\n                    \"default\": 2000000\n                }\n            },\n            \"required\": [\"session_id\", \"message\"]\n        }\n    \n    async def execute(self, session_id: str, message: str, \n                     context_files: List[str] = None, \n                     max_context_lines: int = 500,\n                     max_total_context_lines: int = 2000000, **kwargs) -> str:\n        \"\"\"Continue a session with optional file context.\"\"\"\n        try:\n            session = self.session_manager.get_session(session_id)\n            if not session:\n                return f\"Session {session_id} not found\"\n            \n            # Build message with context if provided\n            full_message = message\n            if context_files:\n                context_content, metadata = ContextLoader.load_context(\n                    context_files,\n                    max_lines_per_file=max_context_lines,\n                    max_total_lines=max_total_context_lines,\n                    context_type='general'\n                )\n                if context_content:\n                    full_message = f\"{message}\\n\\nContext from files:\\n{context_content}\"\n                    if metadata and metadata.get('files_processed', 0) > 0:\n                        full_message += f\"\\n\\n[Loaded {metadata['files_processed']} files, {metadata.get('total_lines', 0)} lines]\"\n            \n            # Add user message\n            self.session_manager.add_message(session_id, \"user\", full_message)\n            \n            # Build conversation history\n            messages = [{\"role\": msg[\"role\"], \"content\": msg[\"content\"]} \n                       for msg in session[\"messages\"]]\n            \n            # Get response from Grok\n            response = await self.grok_client.ask_with_history(\n                messages=messages,\n                stream=False\n            )\n            \n            # Add assistant response\n            self.session_manager.add_message(session_id, \"assistant\", response.content)\n            \n            return response.content\n            \n        except Exception as e:\n            logger.error(f\"Error continuing session: {e}\")\n            return f\"Error: {str(e)}\"\n    \n\n\n--- File: lib/tools/health.py ---\n\"\"\"\nHealth check tool for monitoring server status.\n\"\"\"\n\nimport time\nfrom typing import Any, Dict\nfrom .base import BaseTool\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\nclass HealthCheckTool(BaseTool):\n    \"\"\"Tool for checking server and API health.\"\"\"\n    \n    def __init__(self, grok_client):\n        super().__init__(grok_client)\n        self.start_time = time.time()\n    \n    @property\n    def name(self) -> str:\n        return \"grok_health\"\n    \n    @property\n    def description(self) -> str:\n        return \"Check server and API health status\"\n    \n    @property\n    def input_schema(self) -> Dict[str, Any]:\n        return {\n            \"type\": \"object\",\n            \"properties\": {\n                \"verbose\": {\n                    \"type\": \"boolean\",\n                    \"description\": \"Include detailed diagnostics\",\n                    \"default\": False\n                }\n            }\n        }\n    \n    async def execute(self, verbose: bool = False, **kwargs) -> str:\n        \"\"\"Check health status.\"\"\"\n        try:\n            # Check server uptime\n            uptime = int(time.time() - self.start_time)\n            \n            # Test API connectivity\n            api_status = \"unknown\"\n            latency_ms = -1\n            \n            start = time.time()\n            try:\n                response = await self.grok_client.ask(\n                    prompt=\"ping\",\n                    max_tokens=1,\n                    stream=False\n                )\n                api_status = \"connected\" if response else \"error\"\n                latency_ms = int((time.time() - start) * 1000)\n            except Exception as e:\n                api_status = \"disconnected\"\n                logger.error(f\"API health check failed: {e}\")\n            \n            # Build response\n            health = {\n                \"server\": \"healthy\",\n                \"api\": api_status,\n                \"latency_ms\": latency_ms,\n                \"uptime_seconds\": uptime\n            }\n            \n            if verbose:\n                health[\"diagnostics\"] = {\n                    \"version\": \"0.8.0\",\n                    \"features\": {\n                        \"streaming\": True,\n                        \"sessions\": True,\n                        \"context\": True,\n                        \"caching\": True\n                    },\n                    \"limits\": {\n                        \"max_context_tokens\": 10000,\n                        \"max_session_turns\": 10,\n                        \"cache_ttl_seconds\": 3600\n                    }\n                }\n            \n            # Format as string\n            result = f\"Health Status:\\n\"\n            result += f\"  Server: {health['server']}\\n\"\n            result += f\"  API: {health['api']}\\n\"\n            result += f\"  Latency: {health['latency_ms']}ms\\n\"\n            result += f\"  Uptime: {health['uptime_seconds']}s\\n\"\n            \n            if verbose and \"diagnostics\" in health:\n                result += \"\\nDiagnostics:\\n\"\n                diag = health[\"diagnostics\"]\n                result += f\"  Version: {diag['version']}\\n\"\n                result += f\"  Features: {', '.join(k for k, v in diag['features'].items() if v)}\\n\"\n            \n            return result\n            \n        except Exception as e:\n            logger.error(f\"Error in health check: {e}\")\n            return f\"Health check failed: {str(e)}\"\n\nLet's discuss: Analyze this codebase structure",
      "timestamp": "2025-09-20T10:23:54.445767"
    },
    {
      "role": "assistant",
      "content": "# Analysis of the Grok MCP Server Library Codebase Structure\n\nThank you for sharing this codebase! It looks like a well-architected Python library designed to facilitate intelligent, context-aware discussions with xAI's Grok AI model. The project appears to be building a \"MCP Server\" (possibly Multi-Conversation Protocol or similar) that integrates API calls, session management, storage, context analysis, and extensible tools. I'll break down the structure step by step, highlighting the organization, key components, strengths, potential improvements, and overall design patterns. This analysis is based on the provided files, assuming a standard Python package layout.\n\n## 1. **High-Level Overview**\n   - **Purpose**: The library enables structured, multi-turn conversations with Grok, incorporating features like file-based context loading, persistent sessions, checkpointing for recovery, and baseline document generation. It's geared toward developer workflows (e.g., code analysis, debugging, optimization) by intelligently gathering and analyzing project context.\n   - **Version & Scope**: From `__init__.py`, the version is \"0.1.0\". It's modular, with core classes for API interaction, storage, and analysis, plus a tools subpackage for extensibility (likely for integration with frameworks like LangChain or custom servers).\n   - **Dependencies**: Relies on `asyncio`, `openai` (for API client), `aiofiles`, `pathlib`, `dataclasses`, `logging`, `json`, `uuid`, `hashlib`, `glob`, `fnmatch`, and standard libs. No heavy external deps beyond OpenAI's SDK, keeping it lightweight.\n   - **Async-First Design**: Heavy use of `asyncio` for I/O-bound operations (e.g., file reads, API calls), making it suitable for concurrent, scalable applications.\n   - **Package Structure** (inferred from files):\n     ```\n     lib/\n     \u251c\u2500\u2500 __init__.py          # Exports core classes\n     \u251c\u2500\u2500 grok_client.py       # API wrapper\n     \u251c\u2500\u2500 storage_manager.py   # Persistence layer\n     \u251c\u2500\u2500 session_manager.py   # Session orchestration\n     \u251c\u2500\u2500 context_analyzer.py  # Question/context intelligence\n     \u251c\u2500\u2500 baseline_generator.py # Document generation\n     \u2514\u2500\u2500 tools/\n         \u251c\u2500\u2500 __init__.py      # Tool exports\n         \u251c\u2500\u2500 base.py          # Abstract base for tools\n         \u251c\u2500\u2500 ask.py           # Simple Q&A tool\n         \u251c\u2500\u2500 discuss.py       # Multi-turn discussion tool\n         \u251c\u2500\u2500 session.py       # Session management tools\n         \u251c\u2500\u2500 context.py       # Context-aware Q&A\n         \u251c\u2500\u2500 health.py        # Monitoring tool\n         \u2514\u2500\u2500 context_loader.py # File loading utility\n     ```\n     This follows Python best practices: a flat core module with a subpackage for pluggable tools.\n\n   - **Key Themes**:\n     - **Modularity**: Separation of concerns (API, storage, analysis, tools).\n     - **Resilience**: Features like retries, checkpointing, LRU eviction, and error handling.\n     - **Developer-Friendly**: Supports file globbing, line ranges, token estimation, and quality scoring.\n     - **Scalability**: In-memory caching with disk persistence; configurable limits (e.g., max sessions, token budgets).\n\n## 2. **Core Components Breakdown**\nI'll analyze each major file/module, focusing on responsibilities, strengths, and interconnections.\n\n### **grok_client.py**\n   - **Role**: Thin wrapper around xAI's Grok API using `AsyncOpenAI` client. Handles authentication, retries (exponential backoff for rate limits), streaming, and token tracking.\n   - **Key Features**:\n     - Methods: `ask()` (single query), `stream_ask()` (token-by-token), `ask_with_history()` (multi-turn).\n     - Dataclass: `GrokResponse` for structured outputs.\n     - Defaults: Model=\"grok-4-fast-reasoning\", temperature=0.7, max_retries=3.\n   - **Strengths**: Robust error handling; rough token estimation (chars/4). Integrates seamlessly with OpenAI's SDK.\n   - **Interconnections**: Used by all tools (e.g., `AskTool`, `DiscussTool`) as the API gateway.\n   - **Observations**: Streaming is implemented but not always used (e.g., defaults to non-stream in tools). Could add caching for repeated prompts.\n\n### **storage_manager.py**\n   - **Role**: Local file-based persistence for sessions, responses, and baselines. Uses JSON for sessions and Markdown for documents.\n   - **Key Features**:\n     - Directories: `sessions/`, `responses/`, `baselines/`, with metadata.json for indexing.\n     - Async I/O with `aiofiles` for non-blocking saves/loads.\n     - Search: Basic text search in responses; hashing for indexing.\n     - Cleanup: `cleanup_old_sessions()` for retention policies.\n     - Stats: `get_storage_stats()` for monitoring (size, counts).\n   - **Strengths**: Size limits (e.g., 50MB/session); handles large files gracefully. Metadata enables quick listing/searching.\n   - **Interconnections**: Powers `SessionManager`; used in tools for saving outputs.\n   - **Observations**: Relies on local FS\u2014could extend to cloud storage (e.g., S3). Search is naive (string matching); integrate with Whoosh or Elasticsearch for better NLP search.\n\n### **session_manager.py**\n   - **Role**: Orchestrates multi-turn discussions with state management, including checkpointing, pausing/resuming, and memory optimization.\n   - **Key Features**:\n     - Dataclass: `Session` for state (topic, iterations, responses, checkpoints).\n     - LRU Eviction: Tracks access times; evicts when exceeding `MAX_ACTIVE_SESSIONS` (default 100).\n     - Checkpointing: Periodic async tasks (every 60s) for recovery.\n     - Quality Scoring: Heuristic-based (e.g., code blocks, headers) for responses.\n     - Lifecycle: Create, update, pause/resume, recover, cleanup inactive sessions.\n     - Stats: `get_session_stats()` for monitoring.\n   - **Strengths**: Crash recovery via checkpoints; async cleanup tasks. Handles token limits and iteration caps.\n   - **Interconnections**: Integrates with `StorageManager` for persistence; used by `DiscussTool` and session tools.\n   - **Observations**: Sophisticated but complex\u2014`calculate_quality_score()` is rule-based and could use ML (e.g., via Hugging Face). No distributed session support (e.g., Redis).\n\n### **context_analyzer.py**\n   - **Role**: NLP-lite analysis of questions to gather relevant project context (files, snippets).\n   - **Key Features**:\n     - Question Classification: Patterns for types (implementation, debugging, optimization, etc.).\n     - Extraction: Keywords, entities (functions/classes/files), file references.\n     - Gathering: Walks project dir; scores relevance (keywords, size penalties); fits token budget.\n     - Dataclass: `ContextItem` for scored items.\n   - **Strengths**: Intelligent filtering (e.g., skip node_modules); token estimation; type-specific associations (e.g., test files for \"testing\" questions).\n   - **Interconnections**: Used in `DiscussTool` and `AskWithContextTool`; feeds into `BaselineGenerator`.\n   - **Observations**: Regex-based entity extraction is solid but basic\u2014could enhance with spaCy/NLTK for better NER. Project root is optional (defaults to cwd), which is flexible.\n\n### **baseline_generator.py**\n   - **Role**: Creates structured Markdown \"baseline\" documents for discussions, summarizing analysis and context.\n   - **Key Features**:\n     - Sections: Executive summary, problem analysis, context summary, requirements, expert perspectives, approach, questions, success criteria.\n     - Dataclass: `BaselineSection` with priority and token estimates.\n     - Budgeting: Truncates to fit `token_budget` (default 10k).\n   - **Strengths**: Tailored to question type (e.g., debugging vs. optimization); promotes structured thinking.\n   - **Interconnections**: Uses `ContextAnalyzer` outputs; saved via `StorageManager`.\n   - **Observations**: Heavily template-driven\u2014great for consistency, but could dynamically generate sections via Grok calls for more adaptability.\n\n### **tools/ Subpackage**\n   - **Role**: Extensible tools for MCP integration (e.g., as LangChain tools or API endpoints). Each inherits from `BaseTool` (with schema for JSON inputs).\n   - **Key Tools**:\n     - **ask.py (AskTool)**: Simple Q&A; backward-compatible.\n     - **discuss.py (DiscussTool)**: Multi-turn with pagination, file context, expert mode. Uses `ContextLoader` for advanced loading (globs, line ranges, exclusions).\n     - **session.py**: `SessionManager` class + tools for listing/continuing sessions. Simple JSON-based persistence.\n     - **context.py (AskWithContextTool)**: Q&A with file loading.\n     - **health.py (HealthCheckTool)**: Uptime, API latency, diagnostics.\n     - **context_loader.py**: Utility for loading files/directories with filters (extensions, excludes, recursion). Handles globs and line slicing.\n   - **Strengths**: JSON schemas for validation; async execution. `ContextLoader` is powerful (e.g., `**/*.py` patterns, max lines).\n   - **Observations**: Tools are async-ready but some (e.g., `AskTool`) disable streaming by default. Session persistence here is simpler than the core `SessionManager`\u2014potential for unification. Excludes common junk (e.g., `__pycache__`).\n\n## 3. **Design Patterns & Architecture**\n   - **Layered Architecture**:\n     - **API Layer**: `GrokClient` (external integration).\n     - **Business Logic**: `SessionManager`, `ContextAnalyzer`, `BaselineGenerator`.\n     - **Data Layer**: `StorageManager`.\n     - **Extensibility**: Tools as plugins.\n   - **Patterns Used**:\n     - **Dataclasses**: For structured data (e.g., `Session`, `ContextItem`).\n     - **Async Patterns**: Tasks for background work (checkpoints, cleanup).\n     - **Factory/Builder**: E.g., `_resolve_file_spec()` in `ContextLoader`.\n     - **Observer-like**: Access time tracking for LRU.\n     - **Heuristics**: Token estimation, quality scoring, relevance (no ML deps, keeping it lightweight).\n   - **Configuration**: Env vars (e.g., `MAX_ACTIVE_SESSIONS`, `XAI_API_KEY`) for flexibility.\n   - **Error Handling**: Comprehensive logging; graceful degradation (e.g., skip large files).\n   - **Testing Gaps**: No visible tests\u2014add pytest for units (e.g., token estimation) and integration (e.g., mock API).\n\n## 4. **Strengths**\n   - **Comprehensive**: Covers full lifecycle (ask \u2192 discuss \u2192 persist \u2192 recover).\n   - **Performance-Minded**: Token budgets, truncation, LRU, async I/O.\n   - **Usable**: Rich context loading (e.g., line ranges for debugging specific code sections).\n   - **Maintainable**: Clean separation; good logging; docstrings.\n   - **Extensible**: Tools schema allows easy addition (e.g., new analysis tools).\n\n## 5. **Potential Improvements & Suggestions**\n   - **Unification**: The tools/session.py has a simpler `SessionManager` than core/session_manager.py\u2014merge or clarify roles.\n   - **Advanced Features**:\n     - Integrate real NLP (e.g., transformers for better entity extraction).\n     - Add vector search (e.g., FAISS) for semantic context retrieval.\n     - Support remote storage (e.g., MongoDB for sessions).\n     - Webhooks or real-time streaming for UI integrations.\n   - **Security**: API key from env is good, but add key rotation/validation. Sanitize file paths to prevent path traversal.\n   - **Documentation**: Add README with setup/examples. Type hints are good but could use mypy.\n   - **Edge Cases**: Handle very large projects (e.g., gitignore integration for exclusions). Test with real xAI API limits.\n   - **Next Steps**: If this is for a server, expose via FastAPI/Flask. For production, add metrics (Prometheus) and distributed locking for sessions.\n\nThis codebase is impressive for a 0.1.0 version\u2014it's production-ready for small-scale use and has clear paths for growth. What aspect would you like to dive deeper into? For example, how it handles a specific workflow like debugging code, or suggestions for implementing a new feature?",
      "timestamp": "2025-09-20T10:24:11.263924"
    }
  ],
  "status": "completed"
}